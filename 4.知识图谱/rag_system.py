"""
RAGç³»ç»Ÿæ¨¡å—
æ•´åˆå‘é‡æ£€ç´¢å’ŒçŸ¥è¯†å›¾è°±ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
"""
from typing import Dict, List
from neo4j_connection import Neo4jConnection
from neo4j_query import Neo4jQuery
from vector_search import VectorSearch
from embedding_service import EmbeddingService
from llm_service import LLMService
from config import kg_schema


class RAGSystem:
    """
    RAGç³»ç»Ÿç±»
    æ•´åˆå‘é‡æ£€ç´¢å’ŒçŸ¥è¯†å›¾è°±æ£€ç´¢
    """

    def __init__(self, connection: Neo4jConnection = None):
        """
        åˆå§‹åŒ–RAGç³»ç»Ÿ

        ã€è¾“å…¥ç¤ºä¾‹ã€‘
        conn = Neo4jConnection()
        conn.connect()
        rag = RAGSystem(conn)

        ã€è¾“å‡ºç¤ºä¾‹ã€‘
        None (ç³»ç»Ÿå·²åˆå§‹åŒ–)
        """
        self.connection = connection or Neo4jConnection()

        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.embed_service = EmbeddingService()
        self.llm_service = LLMService()
        self.query = Neo4jQuery(self.connection)
        self.search = VectorSearch(self.connection, self.embed_service)

        # åŠ è½½åµŒå…¥å‘é‡
        self.search.load_embeddings_from_db()

    def process_query(self, query_text: str,
                      entity_types: List[str] = None,
                      relation_types: List[str] = None,
                      depth: int = 2,
                      similarity_threshold: float = 0.7,
                      top_k: int = 5) -> Dict:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢

        ã€è¾“å…¥ç¤ºä¾‹ã€‘
        result = rag.process_query(
            query_text="é˜¿å¸åŒ¹æ—å¯ä»¥æ²»ç–—ä»€ä¹ˆï¼Ÿ",
            entity_types=["è¯ç‰©", "ç—‡çŠ¶", "ç–¾ç—…"],
            relation_types=["æ²»ç–—", "å¯¼è‡´"],
            depth=2,
            similarity_threshold=0.75,
            top_k=5
        )

        ã€è¾“å‡ºç¤ºä¾‹ã€‘
        {
            "answer": "æ ¹æ®çŸ¥è¯†å›¾è°±ï¼Œé˜¿å¸åŒ¹æ—ä¸»è¦ç”¨äºæ²»ç–—å¤´ç—›ã€å‘çƒ­ç­‰ç—‡çŠ¶...",
            "kg_results": [...],
            "similar_entities": [...],
            "processing_time": 2.34
        }
        """
        import time
        start_time = time.time()

        print(f"\nğŸ” å¤„ç†æŸ¥è¯¢: {query_text}")

        # 1. æå–æŸ¥è¯¢ä¸­çš„å®ä½“
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå®ä½“ç±»å‹å’Œå…³ç³»ç±»å‹ï¼Œä»kg_schema.jsonè¯»å–
        entity_types = entity_types or kg_schema.get_entity_types()
        relation_types = relation_types or kg_schema.get_relationship_types()

        extraction_result = self.llm_service.extract_entities_relations(
            query_text, entity_types, relation_types
        )

        entities = extraction_result.get("entities", [])

        # 2. å‘é‡æ£€ç´¢ç›¸ä¼¼å®ä½“
        entity_texts = [
            f"{e.get('type', 'å®ä½“')}: {e['name']}"
            for e in entities
        ]

        all_similar_entity_ids = set()

        for entity_text in entity_texts:
            similar_entities = self.search.search_similar_entities(
                entity_text,
                threshold=similarity_threshold,
                top_k=top_k
            )

            for entity in similar_entities:
                all_similar_entity_ids.add(entity["id"])

        print(f"ğŸ” æ‰¾åˆ° {len(all_similar_entity_ids)} ä¸ªç›¸ä¼¼å®ä½“")

        # 3. çŸ¥è¯†å›¾è°±æŸ¥è¯¢
        kg_results = []
        if all_similar_entity_ids:
            kg_results = self.query.query_by_entities(
                list(all_similar_entity_ids),
                depth=depth
            )

        print(f"ğŸ“Š æŸ¥è¯¢åˆ° {len(kg_results)} æ¡å…³ç³»")

        # 4. ç”Ÿæˆç­”æ¡ˆ
        vdb_results = [result.get("source", "") for result in kg_results[:5]]
        answer = self.llm_service.generate_rag_answer(
            query_text,
            kg_results,
            vdb_results
        )

        processing_time = time.time() - start_time

        return {
            "answer": answer,
            "kg_results": kg_results[:10],
            "similar_entities_count": len(all_similar_entity_ids),
            "processing_time": processing_time
        }

    def simple_query(self, query_text: str) -> str:
        """
        ç®€å•æŸ¥è¯¢æ¥å£

        ã€è¾“å…¥ç¤ºä¾‹ã€‘
        answer = rag.simple_query("é˜¿å¸åŒ¹æ—æœ‰ä»€ä¹ˆä½œç”¨ï¼Ÿ")

        ã€è¾“å‡ºç¤ºä¾‹ã€‘
        "æ ¹æ®çŸ¥è¯†å›¾è°±ï¼Œé˜¿å¸åŒ¹æ—ä¸»è¦ç”¨äºæ²»ç–—å¤´ç—›ã€å‘çƒ­ç­‰ç—‡çŠ¶..."
        """
        result = self.process_query(query_text)
        return result["answer"]

    def get_graph_data(self, limit: int = 100) -> Dict:
        """
        è·å–å›¾è°±æ•°æ®ç”¨äºå¯è§†åŒ–

        ã€è¾“å…¥ç¤ºä¾‹ã€‘
        data = rag.get_graph_data(limit=50)

        ã€è¾“å‡ºç¤ºä¾‹ã€‘
        {
            "nodes": [...],
            "links": [...]
        }
        """
        return self.query.get_all_graph(limit=limit)

    def search_graph(self, keyword: str) -> Dict:
        """
        æœç´¢å›¾è°±

        ã€è¾“å…¥ç¤ºä¾‹ã€‘
        data = rag.search_graph("é˜¿å¸åŒ¹æ—")

        ã€è¾“å‡ºç¤ºä¾‹ã€‘
        {
            "nodes": [...],
            "links": [...]
        }
        """
        return self.query.search_by_keyword(keyword)

    def close(self):
        """
        å…³é—­ç³»ç»Ÿ

        ã€è¾“å…¥ç¤ºä¾‹ã€‘
        rag.close()

        ã€è¾“å‡ºç¤ºä¾‹ã€‘
        None (ç³»ç»Ÿå·²å…³é—­)
        """
        self.embed_service.close()
        self.llm_service.close()


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹1: åˆå§‹åŒ–ç³»ç»Ÿ
    print("ç¤ºä¾‹1: åˆå§‹åŒ–RAGç³»ç»Ÿ")
    conn = Neo4jConnection()
    conn.connect()

    rag = RAGSystem(conn)

    # ç¤ºä¾‹2: å¤„ç†æŸ¥è¯¢
    print("\nç¤ºä¾‹2: å¤„ç†æŸ¥è¯¢")
    queries = [
        "é˜¿å¸åŒ¹æ—å¯ä»¥æ²»ç–—ä»€ä¹ˆï¼Ÿ",
        "å¤´ç—›æœ‰ä»€ä¹ˆç—‡çŠ¶ï¼Ÿ",
        "æ„Ÿå†’ä¼šå¯¼è‡´ä»€ä¹ˆï¼Ÿ"
    ]

    for query in queries:
        print(f"\né—®é¢˜: {query}")
        result = rag.process_query(query)
        print(f"ç­”æ¡ˆ: {result['answer'][:100]}...")
        print(f"å¤„ç†æ—¶é—´: {result['processing_time']:.2f}s")

    # ç¤ºä¾‹3: ç®€å•æŸ¥è¯¢
    print("\nç¤ºä¾‹3: ç®€å•æŸ¥è¯¢")
    answer = rag.simple_query("é˜¿å¸åŒ¹æ—æœ‰ä»€ä¹ˆå‰¯ä½œç”¨ï¼Ÿ")
    print(f"ç­”æ¡ˆ: {answer}")

    # ç¤ºä¾‹4: è·å–å›¾è°±æ•°æ®
    print("\nç¤ºä¾‹4: è·å–å›¾è°±æ•°æ®")
    graph_data = rag.get_graph_data(limit=10)
    print(f"å›¾è°±åŒ…å« {len(graph_data['nodes'])} ä¸ªèŠ‚ç‚¹")
    print(f"å›¾è°±åŒ…å« {len(graph_data['links'])} æ¡å…³ç³»")

    # ç¤ºä¾‹5: æœç´¢å›¾è°±
    print("\nç¤ºä¾‹5: æœç´¢å›¾è°±")
    search_result = rag.search_graph("é˜¿å¸åŒ¹æ—")
    print(f"æ‰¾åˆ° {len(search_result['nodes'])} ä¸ªç›¸å…³èŠ‚ç‚¹")

    rag.close()
    conn.close()
