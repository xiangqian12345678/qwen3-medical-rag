"""
ä¸»ç¨‹åºå…¥å£
æä¾›å®Œæ•´çš„åŸºäºçŸ¥è¯†å›¾è°±çš„RAGå•è½®ä¼šè¯ç¤ºä¾‹
"""
from embedding_service import EmbeddingService
from llm_service import LLMService
from neo4j_connection import Neo4jConnection
from neo4j_operations import Neo4jOperations
from neo4j_query import Neo4jQuery
from neo4j_save import Neo4jSave
from rag_system import RAGSystem
from text_processor import TextProcessor


def example_1_basic_operations():
    """
    ç¤ºä¾‹1: åŸºç¡€æ•°æ®åº“æ“ä½œ
    æ¼”ç¤ºå¦‚ä½•åˆ›å»ºå®ä½“å’Œå…³ç³»
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹1: åŸºç¡€æ•°æ®åº“æ“ä½œ")
    print("=" * 60)

    # è¿æ¥æ•°æ®åº“
    conn = Neo4jConnection()
    if not conn.connect():
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
        return

    # åˆ›å»ºæ“ä½œå¯¹è±¡
    ops = Neo4jOperations(conn)

    # åˆ›å»ºå®ä½“
    print("\nğŸ“ åˆ›å»ºå®ä½“...")
    aspirin_id = ops.create_entity(
        name="é˜¿å¸åŒ¹æ—",
        entity_type="è¯ç‰©",
        properties={"æˆåˆ†": "ä¹™é…°æ°´æ¨é…¸", "å‰‚é‡": "100mg"}
    )
    print(f"  åˆ›å»ºè¯ç‰©: é˜¿å¸åŒ¹æ—, ID: {aspirin_id}")

    headache_id = ops.create_entity("å¤´ç—›", "ç—‡çŠ¶", {"æè¿°": "å¤´éƒ¨ç–¼ç—›"})
    print(f"  åˆ›å»ºç—‡çŠ¶: å¤´ç—›, ID: {headache_id}")

    fever_id = ops.create_entity("å‘çƒ­", "ç—‡çŠ¶", {"æè¿°": "ä½“æ¸©å‡é«˜"})
    print(f"  åˆ›å»ºç—‡çŠ¶: å‘çƒ­, ID: {fever_id}")

    # åˆ›å»ºå…³ç³»
    print("\nğŸ“ åˆ›å»ºå…³ç³»...")
    rel_id1 = ops.create_relationship(
        source_id=aspirin_id,
        target_id=headache_id,
        rel_type="æ²»ç–—",
        properties={}
    )
    print(f"  åˆ›å»ºå…³ç³»: é˜¿å¸åŒ¹æ— æ²»ç–— å¤´ç—›, ID: {rel_id1}")

    rel_id2 = ops.create_relationship(
        source_id=aspirin_id,
        target_id=fever_id,
        rel_type="æ²»ç–—",
        properties={}
    )
    print(f"  åˆ›å»ºå…³ç³»: é˜¿å¸åŒ¹æ— æ²»ç–— å‘çƒ­, ID: {rel_id2}")

    # æŸ¥è¯¢å®ä½“
    print("\nğŸ“ æŸ¥è¯¢å®ä½“...")
    entity = ops.get_entity_by_id(aspirin_id)
    print(f"  å®ä½“è¯¦æƒ…: {entity}")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“ è·å–ç»Ÿè®¡ä¿¡æ¯...")
    stats = ops.get_statistics()
    print(f"  å®ä½“æ€»æ•°: {stats['entities']}")
    print(f"  å…³ç³»æ€»æ•°: {stats['relationships']}")

    conn.close()


def example_2_extract_and_save():
    """
    ç¤ºä¾‹2: ä»æ–‡æœ¬æå–å¹¶ä¿å­˜çŸ¥è¯†
    æ¼”ç¤ºä½¿ç”¨å¤§æ¨¡å‹ä»æ–‡æœ¬æå–å®ä½“å…³ç³»å¹¶ä¿å­˜åˆ°æ•°æ®åº“
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹2: ä»æ–‡æœ¬æå–å¹¶ä¿å­˜çŸ¥è¯†")
    print("=" * 60)

    # åˆå§‹åŒ–æœåŠ¡
    conn = Neo4jConnection()
    if not conn.connect():
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
        return

    embed_service = EmbeddingService()
    llm_service = LLMService()

    saver = Neo4jSave(conn, embed_service)

    # ç¤ºä¾‹æ–‡æœ¬
    text = """
    é˜¿å¸åŒ¹æ—æ˜¯ä¸€ç§éç”¾ä½“æŠ—ç‚è¯ï¼Œå¸¸ç”¨äºæ²»ç–—å¤´ç—›ã€å…³èŠ‚ç—›å’Œå‘çƒ­ã€‚
    å¸ƒæ´›èŠ¬ä¹Ÿæ˜¯ä¸€ç§å¸¸ç”¨çš„éç”¾ä½“æŠ—ç‚è¯ï¼Œä¸»è¦ç”¨äºç¼“è§£è½»ä¸­åº¦ç–¼ç—›å’Œå‘çƒ­ã€‚
    æ„Ÿå†’ä¼šå¯¼è‡´å¤´ç—›ã€å‘çƒ­ã€æµé¼»æ¶•ç­‰ç—‡çŠ¶ã€‚
    """

    print(f"\nğŸ“ å¤„ç†æ–‡æœ¬: {text[:50]}...")

    # æå–å¹¶ä¿å­˜çŸ¥è¯†ï¼ˆè‡ªåŠ¨ä»kg_schema.jsonè¯»å–å®ä½“ç±»å‹å’Œå…³ç³»ç±»å‹ï¼‰
    success = saver.save_text_knowledge(
        text,
        llm_service
    )

    if success:
        print("âœ… çŸ¥è¯†ä¿å­˜æˆåŠŸ")
    else:
        print("âŒ çŸ¥è¯†ä¿å­˜å¤±è´¥")

    embed_service.close()
    llm_service.close()
    conn.close()


def example_3_query_knowledge():
    """
    ç¤ºä¾‹3: æŸ¥è¯¢çŸ¥è¯†å›¾è°±
    æ¼”ç¤ºå¦‚ä½•æŸ¥è¯¢çŸ¥è¯†å›¾è°±
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹3: æŸ¥è¯¢çŸ¥è¯†å›¾è°±")
    print("=" * 60)

    # è¿æ¥æ•°æ®åº“
    conn = Neo4jConnection()
    if not conn.connect():
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
        return

    query = Neo4jQuery(conn)

    # å…³é”®å­—æœç´¢
    print("\nğŸ“ å…³é”®å­—æœç´¢...")
    result = query.search_by_keyword("é˜¿å¸åŒ¹æ—", limit=20)
    print(f"  æ‰¾åˆ° {len(result['nodes'])} ä¸ªèŠ‚ç‚¹")
    print(f"  æ‰¾åˆ° {len(result['links'])} æ¡å…³ç³»")

    # ä¸‰å…ƒç»„æŸ¥è¯¢
    print("\nğŸ“ ä¸‰å…ƒç»„æŸ¥è¯¢...")
    result = query.query_triples(head="é˜¿å¸åŒ¹æ—", relation="æ²»ç–—")
    print(f"  æ‰¾åˆ° {len(result['links'])} æ¡åŒ¹é…å…³ç³»")

    # è·å–æ•´ä¸ªå›¾è°±
    print("\nğŸ“ è·å–æ•´ä¸ªå›¾è°±...")
    graph = query.get_all_graph(limit=50)
    print(f"  å›¾è°±åŒ…å« {len(graph['nodes'])} ä¸ªèŠ‚ç‚¹")
    print(f"  å›¾è°±åŒ…å« {len(graph['links'])} æ¡å…³ç³»")

    conn.close()


def example_4_rag_query():
    """
    ç¤ºä¾‹4: RAGæŸ¥è¯¢
    æ¼”ç¤ºå®Œæ•´çš„RAGæŸ¥è¯¢æµç¨‹
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹4: RAGæŸ¥è¯¢")
    print("=" * 60)

    # åˆå§‹åŒ–RAGç³»ç»Ÿ
    conn = Neo4jConnection()
    if not conn.connect():
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
        return

    rag = RAGSystem(conn)

    # æŸ¥è¯¢ç¤ºä¾‹
    queries = [
        "é˜¿å¸åŒ¹æ—å¯ä»¥æ²»ç–—ä»€ä¹ˆï¼Ÿ",
        "å¤´ç—›æœ‰ä»€ä¹ˆç—‡çŠ¶ï¼Ÿ",
        "æ„Ÿå†’ä¼šå¯¼è‡´ä»€ä¹ˆç—‡çŠ¶ï¼Ÿ"
    ]

    print("\nğŸ“ å¤„ç†ç”¨æˆ·æŸ¥è¯¢...")

    for query_text in queries:
        print(f"\né—®é¢˜: {query_text}")
        result = rag.process_query(
            query_text,
            depth=2,
            similarity_threshold=0.7,
            top_k=5
        )

        print(f"ç­”æ¡ˆ: {result['answer']}")
        print(f"å¤„ç†æ—¶é—´: {result['processing_time']:.2f}s")

    rag.close()
    conn.close()


def example_5_process_documents():
    """
    ç¤ºä¾‹5: å¤„ç†æ–‡æ¡£å¹¶æ„å»ºçŸ¥è¯†åº“
    æ¼”ç¤ºä»æ–‡æ¡£æ–‡ä»¶æ‰¹é‡å¤„ç†å¹¶æ„å»ºçŸ¥è¯†åº“
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹5: å¤„ç†æ–‡æ¡£å¹¶æ„å»ºçŸ¥è¯†åº“")
    print("=" * 60)

    # åˆå§‹åŒ–æœåŠ¡
    conn = Neo4jConnection()
    if not conn.connect():
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
        return

    embed_service = EmbeddingService()
    llm_service = LLMService()
    saver = Neo4jSave(conn, embed_service)
    processor = TextProcessor()

    # å¤„ç†æ–‡æ¡£ç›®å½•
    documents_dir = "../data/graph"

    if not os.path.exists(documents_dir):
        print(f"âš ï¸ æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {documents_dir}")
        print("  è¯·ç¡®ä¿åœ¨tmpç›®å½•ä¸‹åˆ›å»ºdocumentsç›®å½•å¹¶æ”¾å…¥æ–‡æ¡£æ–‡ä»¶")
        return

    print(f"\nğŸ“ å¤„ç†æ–‡æ¡£ç›®å½•: {documents_dir}")

    # åŠ è½½æ‰€æœ‰æ–‡æœ¬
    texts = processor.load_text_from_directory(documents_dir)

    if not texts:
        print("âš ï¸ æœªæ‰¾åˆ°å¯å¤„ç†çš„æ–‡æœ¬")
        return

    print(f"å…±åŠ è½½ {len(texts)} æ®µæ–‡æœ¬")

    # åˆ†å‰²å¹¶å¤„ç†æ¯æ®µæ–‡æœ¬ï¼ˆè‡ªåŠ¨ä»kg_schema.jsonè¯»å–å®ä½“ç±»å‹å’Œå…³ç³»ç±»å‹ï¼‰
    for i, text in enumerate(texts[:10]):  # é™åˆ¶å¤„ç†å‰10æ®µæ–‡æœ¬
        print(f"\nå¤„ç†æ–‡æœ¬ {i + 1}/{len(texts)}...")
        print(f"æ–‡æœ¬å†…å®¹: {text[:100]}...")

        saver.save_text_knowledge(
            text,
            llm_service
        )

    print("\nâœ… æ–‡æ¡£å¤„ç†å®Œæˆ")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    ops = Neo4jOperations(conn)
    stats = ops.get_statistics()
    print(f"\nçŸ¥è¯†åº“ç»Ÿè®¡:")
    print(f"  å®ä½“æ€»æ•°: {stats['entities']}")
    print(f"  å…³ç³»æ€»æ•°: {stats['relationships']}")

    embed_service.close()
    llm_service.close()
    conn.close()


def example_6_complete_rag_session():
    """
    ç¤ºä¾‹6: å®Œæ•´çš„RAGå•è½®ä¼šè¯
    æ¼”ç¤ºä»ç”¨æˆ·é—®é¢˜åˆ°ç”Ÿæˆç­”æ¡ˆçš„å®Œæ•´æµç¨‹
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹6: å®Œæ•´çš„RAGå•è½®ä¼šè¯")
    print("=" * 60)

    # åˆå§‹åŒ–ç³»ç»Ÿ
    print("\nğŸ› ï¸ åˆå§‹åŒ–RAGç³»ç»Ÿ...")
    conn = Neo4jConnection()
    if not conn.connect():
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
        return

    rag = RAGSystem(conn)
    print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    # ç”¨æˆ·ä¼šè¯
    print("\n" + "-" * 60)
    print("å¼€å§‹RAGä¼šè¯ (è¾“å…¥ 'quit' é€€å‡º)")
    print("-" * 60)

    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("\nè¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()

        if not user_input:
            continue

        if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
            print("ğŸ‘‹ ä¼šè¯ç»“æŸ")
            break

        print(f"\nğŸ“ æ‚¨çš„é—®é¢˜: {user_input}")

        # å¤„ç†æŸ¥è¯¢ï¼ˆè‡ªåŠ¨ä»kg_schema.jsonè¯»å–å®ä½“ç±»å‹å’Œå…³ç³»ç±»å‹ï¼‰
        result = rag.process_query(
            user_input,
            depth=2,
            similarity_threshold=0.7,
            top_k=5
        )

        # æ˜¾ç¤ºç­”æ¡ˆ
        print("\nğŸ’¡ ç³»ç»Ÿå›ç­”:")
        print(result['answer'])

        # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
        print("\nğŸ“Š å¤„ç†ä¿¡æ¯:")
        print(f"  ç›¸ä¼¼å®ä½“æ•°: {result['similar_entities_count']}")
        print(f"  æ£€ç´¢å…³ç³»æ•°: {len(result['kg_results'])}")
        print(f"  å¤„ç†æ—¶é—´: {result['processing_time']:.2f}s")

    rag.close()
    conn.close()


def main():
    """
    ä¸»å‡½æ•°
    è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    """
    print("=" * 60)
    print("åŸºäºçŸ¥è¯†å›¾è°±çš„RAGç³»ç»Ÿ - å®Œæ•´ç¤ºä¾‹")
    print("=" * 60)

    # è¿è¡Œç¤ºä¾‹
    example_1_basic_operations()
    example_2_extract_and_save()
    example_3_query_knowledge()
    example_4_rag_query()
    example_5_process_documents()
    example_6_complete_rag_session()

    print("\n" + "=" * 60)
    print("æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    # å¯¼å…¥osæ¨¡å—
    import os

    # æ£€æŸ¥documentsç›®å½•
    if not os.path.exists("../data/documents"):
        os.makedirs("../data/documents", exist_ok=True)
        print(" å·²åˆ›å»ºdocumentsç›®å½•")
        print("  è¯·å°†æ–‡æ¡£æ–‡ä»¶æ”¾å…¥æ­¤ç›®å½•åå†è¿è¡Œç¤ºä¾‹5å’Œç¤ºä¾‹6")

    # è¿è¡Œä¸»å‡½æ•°
    main()
