{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 索引优化\n",
    "    1.摘要索引\n",
    "        针对概括性查询问题，摘要索引可以解决\n",
    "    2.父子索引\n",
    "        检索准备精准（靠小块）\n",
    "        回答内容完整（大段 Parent）\n",
    "    3.假设性问题检索\n",
    "        即使用户提问与原文不直接匹配，也能通过“生成相关问题 → 再做向量检索”找到语义更深层、更准确的相关内容\n",
    "    4.元数据过滤\n",
    "        向量检索+元数据过滤，检索准确度更高"
   ],
   "id": "dd4e7062000daabc"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 初始化llm（通义千问）\n",
    "llm = ChatTongyi(model=\"qwen-max\")\n",
    "embeddings_model = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "\n",
    "\n",
    "def test_no_summary():\n",
    "    '''未使用摘要索引'''\n",
    "    docs = [\n",
    "        \"DeepSeek，全称杭州深度求索人工智能基础技术研究有限公司，是一家创新型科技公司 ，成立于2023年7月17日，使用数据蒸馏技术 ，得到更为精炼、有用的数据 。由知名私募巨头幻方量化孕育而生，专注于开发先进的大语言模型（LLM）和相关技术。\",\n",
    "        \"DeepSeek R1是推理模型，遵循 MIT License，通过设置 model='deepseek-reasoner' 即可调用。DeepSeek V3是通用大模型，目前版本号 DeepSeek-V3-0324。通过指定 model='deepseek-chat' 即可调用 DeepSeek V3。\",\n",
    "    ]\n",
    "\n",
    "    query = \"DeepSeek R1模型的开发公司叫什么？\"\n",
    "\n",
    "    # 将文档和查询转换为向量\n",
    "    doc_embeddings = embeddings_model.embed_documents(docs)\n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "\n",
    "    # 计算相似度  余弦相似度：点积（A*B）/模长乘积（A模长*B模长）\n",
    "    similarities = [dot(query_embedding, doc_embedding) / (norm(query_embedding) * norm(doc_embedding)) for\n",
    "                    doc_embedding in doc_embeddings]\n",
    "\n",
    "    print(\"==========================不使用摘要索引======================================\")\n",
    "    # 期望得到文档1,检索出文档2\n",
    "    for i, similarity in enumerate(similarities):\n",
    "        print(f\"第{i + 1}个相似度：\", similarity)\n",
    "\n",
    "\n",
    "def test_summary():\n",
    "    '''使用摘要索引'''\n",
    "    # 假设生成了文档的摘要\n",
    "    summary_docs = [\n",
    "        \"DeepSeek公司介绍\",\n",
    "        \"DeepSeek模型调用说明\"\n",
    "    ]\n",
    "    query = \"DeepSeek R1模型的开发公司叫什么？\"\n",
    "\n",
    "    summary_doc_embeddings = embeddings_model.embed_documents(summary_docs)\n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "\n",
    "    # 计算问题与文档摘要的相似度（基于摘要的检索）\n",
    "    similarities = [dot(query_embedding, summary_doc_embedding) / (norm(query_embedding) * norm(summary_doc_embedding))\n",
    "                    for summary_doc_embedding in summary_doc_embeddings]\n",
    "\n",
    "    print(\"==========================使用摘要索引相似度======================================\")\n",
    "    for i, similarity in enumerate(similarities):\n",
    "        print(f\"第{i + 1}个相似度：\", similarity)\n",
    "\n",
    "\n",
    "def test_summary_index():\n",
    "    # 1.文件路径\n",
    "    RESOURCE_DIR = \"../../data/base/resources\"\n",
    "    TXT_DOCUMENT_PATH = os.path.join(RESOURCE_DIR, \"deepseek百度百科.txt\")\n",
    "\n",
    "    # 2.初始化模型\n",
    "    llm = ChatTongyi(model=\"qwen-max\")\n",
    "    embeddings_model = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "\n",
    "    # 3. 加载本地文件\n",
    "    loader = TextLoader(TXT_DOCUMENT_PATH, encoding='utf-8')\n",
    "    docs = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"块 {i + 1} :   {repr(chunk.page_content[:50])}...\")\n",
    "\n",
    "    # 4.生成摘要\n",
    "    # 创建摘要生成链\n",
    "    chain = (\n",
    "            {\"chunk\": lambda x: x.page_content}\n",
    "            | ChatPromptTemplate.from_template(\"总结下面的文档:\\n\\n{chunk}\")\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 批量生成文档摘要（最大并发数5）\n",
    "    summaries = chain.batch(chunks, {\"max_concurrency\": 5})\n",
    "\n",
    "    for i, summary in enumerate(summaries):\n",
    "        print(f\"块 {i + 1} :   {repr(summary[:50])}...\")\n",
    "\n",
    "    # 5.索引准备\n",
    "    #   InMemoryByteStore 是一个内存中的存储层，用于存储原始文档\n",
    "    #   Chroma 是一个文档向量数据库，用于存储文档摘要的向量表示\n",
    "    # 初始化Chroma实例（用于存储摘要向量）\n",
    "    vectorstore = Chroma(\n",
    "        collection_name=\"summaries\",\n",
    "        embedding_function=embeddings_model\n",
    "    )\n",
    "\n",
    "    # 初始化内存字节存储（用于存储原始文档）\n",
    "    store = InMemoryByteStore()\n",
    "\n",
    "    # 6.索引构建\n",
    "    # 初始化多向量检索器（结合向量存储和文档存储）\n",
    "    id_key = \"doc_id\"\n",
    "    retriever = MultiVectorRetriever(\n",
    "        vectorstore=vectorstore,\n",
    "        byte_store=store,\n",
    "        id_key=id_key,\n",
    "        search_kwargs={\"k\": 1}\n",
    "    )\n",
    "\n",
    "    # 为每个文档生成唯一ID\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in chunks]\n",
    "\n",
    "    # 创建摘要文档列表（包含生成的唯一ID作为对应摘要文档的元数据）\n",
    "    summary_docs = [\n",
    "        Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "        for i, s in enumerate(summaries)\n",
    "    ]\n",
    "\n",
    "    # 将摘要添加到向量数据库\n",
    "    retriever.vectorstore.add_documents(summary_docs)\n",
    "\n",
    "    # 将原始文档存储到字节存储（使用ID关联）\n",
    "    retriever.docstore.mset(list(zip(doc_ids, chunks)))\n",
    "\n",
    "    # 7.检索\n",
    "    def pretty_print_docs(docs):\n",
    "        print(\n",
    "            f\"\\n{'-' * 100}\\n\".join(\n",
    "                [f\"Document {i + 1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    contexts = retriever.invoke('deepseek的企业动态')\n",
    "    pretty_print_docs(contexts)\n",
    "\n",
    "\n",
    "test_no_summary()\n",
    "test_summary()\n",
    "test_summary_index()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2.父子索引\n",
    "import os\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_classic.retrievers import ParentDocumentRetriever\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "from langchain_core.stores import InMemoryStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# 格式化输出内容\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i + 1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# 1.文件路径\n",
    "RESOURCE_DIR = \"../../data/base/resources\"\n",
    "TXT_DOCUMENT_PATH = os.path.join(RESOURCE_DIR, \"deepseek百度百科.txt\")\n",
    "\n",
    "# 2.初始化模型\n",
    "llm = ChatTongyi(model=\"qwen-max\")\n",
    "embeddings_model = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "\n",
    "# 3.加载本地数据\n",
    "loader = TextLoader(TXT_DOCUMENT_PATH, encoding='utf-8')\n",
    "docs = loader.load()\n",
    "# 创建主文档分割器\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_overlap=32, chunk_size=256)\n",
    "# 创建子文档分割器\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_overlap=16, chunk_size=64)\n",
    "\n",
    "# 4.存储准备\n",
    "# 存储小块\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"split_parents\", embedding_function=embeddings_model\n",
    ")\n",
    "# 创建内存存储对象，存储大块\n",
    "store = InMemoryStore()\n",
    "\n",
    "# ================================4. 创建检索器================================\n",
    "# 创建父文档检索器\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    "    search_kwargs={\"k\": 1}\n",
    ")\n",
    "\n",
    "# 5.存储文档\n",
    "retriever.add_documents(docs)\n",
    "\n",
    "# 6.子索引检索\n",
    "sub_docs = vectorstore.similarity_search(\"介绍下DeepSeek和市场占用情况\")\n",
    "print(\"-\" * 20 + \"子索引检索\" + \"-\" * 20)\n",
    "for sub_doc in sub_docs:\n",
    "    print(sub_doc.page_content)\n",
    "\n",
    "# 7.父索引检索\n",
    "print(\"-\" * 20 + \"父索引检索\" + \"-\" * 20)\n",
    "retrieved_docs = retriever.invoke(\"介绍下DeepSeek和市场占用情况\")\n",
    "for retrieved_doc in retrieved_docs:\n",
    "    print(retrieved_doc.page_content)\n"
   ],
   "id": "392ce76d31472a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3.假设性问题检索\n",
    "import os\n",
    "import uuid\n",
    "from typing import List\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_classic.retrievers import MultiVectorRetriever\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.stores import InMemoryByteStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# 格式化输出内容\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i + 1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# 1.文件路径\n",
    "RESOURCE_DIR = \"../../data/base/resources\"\n",
    "TXT_DOCUMENT_PATH = os.path.join(RESOURCE_DIR, \"deepseek百度百科.txt\")\n",
    "\n",
    "# 2.模型准备 模型能力很关键\n",
    "llm = ChatOpenAI(api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "                 base_url=\"https://api.deepseek.com/v1\",\n",
    "                 model=\"deepseek-chat\")\n",
    "embeddings_model = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "\n",
    "# 3.加载数据\n",
    "loader = TextLoader(TXT_DOCUMENT_PATH, encoding='utf-8')\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# 4.生成假设性问题准备\n",
    "class HypotheticalQuestions(BaseModel):\n",
    "    \"\"\"生成假设性问题\"\"\"\n",
    "    questions: List[str] = Field(..., description=\"List of questions\")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"生成一个包含3个假设问题的列表，以下文档可用于回答这些问题:\n",
    "\n",
    "    {doc}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "        {\"doc\": lambda x: x.page_content}\n",
    "        | prompt\n",
    "        | llm.with_structured_output(HypotheticalQuestions) # Tool 模式对 JSON 严格要求 → 中文 + 长文本必炸\n",
    "        | (lambda x: x.questions)\n",
    ")\n",
    "\n",
    "# 5. 构建假设性问题索引\n",
    "# 批量处理所有文档生成假设性问题（最大并行数5）\n",
    "hypothetical_questions = chain.batch(docs, {\"max_concurrency\": 5})\n",
    "print(hypothetical_questions)\n",
    "\n",
    "# 初始化Chroma向量数据库（存储生成的问题向量）\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"hypo-questions\", embedding_function=embeddings_model\n",
    ")\n",
    "\n",
    "# 初始化内存存储（存储原始文档）\n",
    "store = InMemoryByteStore()\n",
    "# 文档标识键名\n",
    "id_key = \"doc_id\"\n",
    "# 配置多向量检索器\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    "    search_kwargs={\"k\": 1}\n",
    ")\n",
    "\n",
    "# 为每个原始文档生成唯一ID\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "# 将生成的问题转换为带元数据的文档对象\n",
    "question_docs = []\n",
    "for i, question_list in enumerate(hypothetical_questions):\n",
    "    question_docs.extend([Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list])\n",
    "\n",
    "retriever.vectorstore.add_documents(question_docs)  # 将问题文档存入向量数据库\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))  # 将原始文档存入字节存储（通过ID关联）\n",
    "\n",
    "# 6. 检索\n",
    "sub_docs = retriever.vectorstore.similarity_search(\"deepseek受到哪些攻击？\")\n",
    "print(\"问题：deepseek受到哪些攻击？\")\n",
    "print(\"similarity_search检索结果：\")\n",
    "print(sub_docs[0].page_content)\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"deepseek受到哪些攻击？\")\n",
    "print(\"问题：deepseek受到哪些攻击？\")\n",
    "print(\"invoke检索结果：\")\n",
    "print(retrieved_docs[0].page_content)\n",
    "\n",
    "# 7.演示案例\n",
    "docs = [\n",
    "    \"\"\"团队协作中的常见障碍：\n",
    "        沟通不畅：团队成员之间缺乏有效的沟通，导致信息传递不准确或不及时。\n",
    "        目标不明确：团队成员对共同目标的理解不一致，导致工作方向不一致。\n",
    "        缺乏信任：团队成员之间缺乏信任，导致合作效率低下。\n",
    "        资源分配不均：团队资源分配不合理，导致部分成员工作量过大，部分成员闲置。\"\"\",\n",
    "\n",
    "    \"\"\"提高团队协作效率的策略：\n",
    "        明确目标与分工：确保每个团队成员都清楚团队的共同目标和自己的具体任务。\n",
    "        建立有效的沟通机制：定期召开团队会议，使用协作工具（如Slack、Microsoft Teams）保持实时沟通。\n",
    "        培养团队信任：通过团队建设活动和透明的沟通机制，增强团队成员之间的信任。\n",
    "        合理分配资源：根据团队成员的技能和工作量，合理分配任务和资源。\"\"\",\n",
    "\n",
    "    \"\"\"远程团队协作的最佳实践：\n",
    "        使用协作工具：利用Zoom、Google Workspace等工具进行远程会议和文档协作。\n",
    "        定期检查进度：通过定期的进度报告和检查，确保远程团队的工作进展顺利。\n",
    "        建立明确的沟通规范：制定远程团队的沟通规则，确保信息传递的准确性和及时性。\"\"\"\n",
    "]\n",
    "\n",
    "query = \"团队沟通不畅怎么办\"\n",
    "doc_embeddings = embeddings_model.embed_documents(docs)\n",
    "query_embedding = embeddings_model.embed_query(query)\n",
    "similarities = [dot(query_embedding, doc_embedding) / (norm(query_embedding) * norm(doc_embedding))\n",
    "                for doc_embedding in doc_embeddings]\n",
    "\n",
    "# 8.未来使用假设性问题\n",
    "print(\"==========================未使用假设性问题索引==========================\")\n",
    "for i, similarity in enumerate(similarities):\n",
    "    print(f\"第{i + 1}个相似度：\", similarity)\n",
    "\n",
    "# 9.使用假设性问题索引\n",
    "chain = (\n",
    "        {\"doc\": lambda x: x}\n",
    "        | prompt\n",
    "        | llm.with_structured_output(HypotheticalQuestions)\n",
    "        | (lambda x: x.questions)\n",
    ")\n",
    "\n",
    "hypothetical_questions = chain.batch(docs, {\"max_concurrency\": 5})\n",
    "for q in hypothetical_questions:\n",
    "    print(q)\n",
    "    print(\"=\" * 150)\n",
    "\n",
    "print(\"==========================使用假设性问题索引==========================\")\n",
    "for hypothetical_question in hypothetical_questions:\n",
    "    hypothetical_question_embeddings = embeddings_model.embed_documents(\n",
    "        [question for question in hypothetical_question])\n",
    "    similarities = [\n",
    "        dot(query_embedding, hypothetical_embedding) / (norm(query_embedding) * norm(hypothetical_embedding)) for\n",
    "        hypothetical_embedding in hypothetical_question_embeddings]\n",
    "    print(similarities)\n"
   ],
   "id": "2262aa58582de72e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4.元数据\n",
    "import os\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_classic.retrievers import SelfQueryRetriever\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 格式化输出内容\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i + 1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# 1.文件路径\n",
    "RESOURCE_DIR = \"../../data/base/resources\"\n",
    "TXT_DOCUMENT_PATH = os.path.join(RESOURCE_DIR, \"deepseek百度百科.txt\")\n",
    "\n",
    "# 2.模型准备 模型能力很关键\n",
    "llm = ChatOpenAI(api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "                 base_url=\"https://api.deepseek.com/v1\",\n",
    "                 model=\"deepseek-chat\")\n",
    "embeddings_model = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "\n",
    "# 3.数据准备==========================\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"小米智能手环6\",\n",
    "        metadata={\"品牌\": \"小米\", \"价格\": 249, \"评分\": 4.6}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"华为FreeBuds Pro无线耳机\",\n",
    "        metadata={\"品牌\": \"华为\", \"价格\": 999, \"评分\": 4.8}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"小米移动电源3\",\n",
    "        metadata={\"品牌\": \"小米\", \"价格\": 99, \"评分\": 4.4}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"华为Mate 40 Pro智能手机\",\n",
    "        metadata={\"品牌\": \"华为\", \"价格\": 6999, \"评分\": 5.0}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"小米AirDots Pro蓝牙耳机\",\n",
    "        metadata={\"品牌\": \"小米\", \"价格\": 299, \"评分\": 4.5}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"华为智能手表GT 2\",\n",
    "        metadata={\"品牌\": \"华为\", \"价格\": 1288, \"评分\": 4.7}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"小米小爱音箱Play\",\n",
    "        metadata={\"品牌\": \"小米\", \"价格\": 169, \"评分\": 4.3}\n",
    "    )\n",
    "]\n",
    "\n",
    "# 4. 构建元数据索引\n",
    "metadata_field_info = [\n",
    "    {\"name\": \"品牌\", \"type\": \"string\", \"description\": \"产品的品牌名称\"},\n",
    "    {\"name\": \"价格\", \"type\": \"integer\", \"description\": \"产品的价格\"},\n",
    "    {\"name\": \"评分\", \"type\": \"float\", \"description\": \"产品的用户评分\"},\n",
    "]\n",
    "\n",
    "# 文档内容描述（指导LLM理解文档内容）\n",
    "document_content_description = \"电子产品的信息\"\n",
    "vectorstore = Chroma.from_documents(docs, embeddings_model, collection_name=\"self-query\")\n",
    "\n",
    "# 5.创建自查询检索器（核心组件）\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")\n",
    "\n",
    "# 6.检索\n",
    "pretty_print_docs(retriever.invoke(\"华为价格5000以上的商品\"))\n"
   ],
   "id": "925aae7450f63ab0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
