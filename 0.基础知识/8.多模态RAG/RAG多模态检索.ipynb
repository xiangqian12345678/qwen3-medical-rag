{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "方案一：基于多模态嵌入模型（Embedding-based Multi-modal RAG）\n",
    "1. 原理\n",
    "    使用 多模态嵌入模型（如 CLIP、SigLIP、OpenCLIP） 将图像与文本映射到同一向量空间\n",
    "    所有数据统一用向量检索（Vector Search）\n",
    "    检索出的图文块被送入多模态模型（如 GPT-4V / Gemini / QwenVL）进行最终答案生成\n",
    "\n",
    "2. 优点\n",
    "    成本最低：大部分推理发生在嵌入模型中，检索速度快\n",
    "    架构简单：所有模态都向量化即可，不需要额外摘要\n",
    "    易扩展：可加入更多模态（音频、视频帧等）\n",
    "\n",
    "3. 缺点\n",
    "    检索质量较差：多模态 embedding 的语义理解能力弱于大模型\n",
    "    图像信息损失明显：embedding 模型对细节不敏感（文本、表格效果更差）\n",
    "    难处理复杂图片（表格、公式、密集文本）\n",
    "\n",
    "方案二：基于多模态大模型（图像摘要 + 文本摘要 + 多模态生成）\n",
    "    速度最慢、成本最高、效果最好\n",
    "1. 原理\n",
    "    使用多模态大模型（如 GPT-4V）对图片进行 高质量图像摘要\n",
    "    对文本通过大模型生成 结构化摘要 或精炼文本\n",
    "    对“图像摘要 + 文本摘要”统一做嵌入 → 检索\n",
    "    检索命中后，将 原始图像 + 原始文本 输入多模态大模型进行最终答案合成。\n",
    "\n",
    "2. 优点\n",
    "    检索效果最好：所有模态都由最强模型统一理解\n",
    "    保真度最高：最终回答阶段重新输入原图，避免摘要损失信息\n",
    "    适用任何复杂场景：表格、手写文字、流程图、PDF、截图等\n",
    "\n",
    "3. 缺点\n",
    "    成本最高：摘要阶段 + 生成阶段都使用大模型\n",
    "    速度最慢：尤其数据量大时，离线摘要成本巨大\n",
    "    维护复杂：摘要质量会影响检索稳定性\n",
    "\n",
    "方案三：基于多模态大模型（图像摘要 + 文本向量检索 + 文本生成）\n",
    "    成本适中、效果居中\n",
    "    为什么说用了图片摘要却又没用？”\n",
    "    因为方案三确实 只在预处理时使用图片摘要，不在生成时再读原图。\n",
    "1. 原理\n",
    "    使用多模态大模型（如 GPT-4V、Gemini、Qwen-VL）对图片生成 一次性高质量摘要\n",
    "    图像摘要被当作纯文本处理\n",
    "    所有检索都基于文本向量（如 text embedding）\n",
    "    最终回答阶段只输入 文本块，不包含原图，不再做多模态生成\n",
    "\n",
    "2. 优点\n",
    "    成本中等：只在预处理用大模型，检索与生成使用便宜模型。\n",
    "    效果比方案一好：因为文本摘要比 embedding 更捕捉语义。\n",
    "    推理速度快：在线阶段全是文本处理。\n",
    "\n",
    "3. 缺点\n",
    "    无法重新理解原图：生成时不再读取图片 → 丢失视觉精度\n",
    "    受摘要质量影响巨大：摘要写得不好 = 永久不准\n",
    "    图像特征过度文本化：复杂图像内容可能被压缩或错译\n",
    "\n",
    "方案对比\n",
    "| 方案                     | 图片是否向量化 | 是否用 LLM 生成图片摘要 | 检索阶段    | 生成阶段是否重新看原图 | 成本 | 效果  |\n",
    "| ----------------------- | ------------ | ------------------- | ---------- | ------------------ | --- | ---- |\n",
    "| 方案一：多模态嵌入          | ✔️          | ❌                  | 向量检索     | 看原图              | 低  | 中偏低 |\n",
    "| 方案二：多模态大模型全链路   | ❌           | ✔️                  | 摘要向量检索 | ✔️ 再看原图         |  高  | 最高  |\n",
    "| 方案三：图片摘要 + 文本检索  | ❌          | ✔️                   | 文本向量检索 | ❌ 不再看原图        | 中  | 中   |\n"
   ],
   "id": "37ec58b79a7015c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.基于多模态向量模型的RAG",
   "id": "f611da34e465cb37"
  },
  {
   "cell_type": "code",
   "id": "45a672fdff00e044",
   "metadata": {},
   "source": [
    "# 1.1 初始化\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import uuid\n",
    "from typing import List\n",
    "\n",
    "import dashscope\n",
    "import markdown\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from pydantic import BaseModel\n",
    "from unstructured.documents.elements import Table, CompositeElement\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# 环境配置\n",
    "os.environ[\"TESSERACT_CMD\"] = \"/usr/bin/tesseract\"\n",
    "\n",
    "# 初始化\n",
    "BASE_DIR = \"/mnt/c/大模型/智泊大模型全栈教程总结/02-教材整理 L2/代码/Langchain/6.langchain高级RAG/data/\"\n",
    "RESOURCE_DIR = BASE_DIR + 'resources/'\n",
    "TOOLS_DIR = BASE_DIR + 'tools/'\n",
    "IMAGE_OUT_DIR = RESOURCE_DIR + 'images/'\n",
    "PDF_PATH = RESOURCE_DIR + \"978-7-5170-2271-8_1.pdf\"\n",
    "RESIZE_IMAGE_DIR = RESOURCE_DIR + \"temp\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.2 基本函数定义\n",
    "def show_plt_img(img_base64):\n",
    "    \"\"\"\n",
    "    用于在 Jupyter Notebook 或类似环境中显示 Base64 编码的图像\n",
    "    1. 使用 f-string 格式化创建一个 HTML 的 <img> 标签\n",
    "    2. 标签的 src 属性使用 Data URL 格式:\n",
    "    3. data:image/jpeg;base64, 表示这是一个 JPEG 图像的 Base64 编码数据\n",
    "    4. 后面接上传入的 img_base64 字符串\n",
    "    5. 使用 display(HTML(...)) 在 Notebook 中渲染这个 HTML 图像标签\n",
    "    \"\"\"\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "    display(HTML(image_html))\n",
    "\n",
    "\n",
    "def encode_image(img_path):\n",
    "    \"\"\"\n",
    "    base64.b64encode(img_data) 将二进制数据编码为 Base64 字节串\n",
    "    .decode('utf-8') 将 Base64 字节串转换为 UTF-8 字符串\n",
    "    返回最终的 Base64 编码字符串\n",
    "    \"\"\"\n",
    "    with open(img_path, \"rb\") as img_file:\n",
    "        img_data = img_file.read()\n",
    "        img_base64 = base64.b64encode(img_data).decode('utf-8')\n",
    "        return img_base64\n",
    "\n",
    "\n",
    "def display_answer(text: str):\n",
    "    \"\"\"\n",
    "    输入参数:\n",
    "    text: 字符串类型，包含文本内容和图像标记的特殊格式字符串\n",
    "    标记格式:使用 <image> 和 </image> 作为图像路径的标记\n",
    "    格式示例: \"这是一些文本<image>path/to/image.jpg</image>更多文本\"\n",
    "    \"\"\"\n",
    "    start_tag = \"<image>\"\n",
    "    end_tag = \"</image>\"\n",
    "\n",
    "    # 根据<image>标签 分割文本：xxx<image>image</image>xxx => ['xxx','image</image>xxx']\n",
    "    parts = text.split(start_tag)\n",
    "    for part in parts:\n",
    "        # 再根据</image>标签 分割文本：xxx => ['xxx'], image</image>xxx => ['image','xxx']\n",
    "        chunks = part.split(end_tag)\n",
    "        if len(chunks) > 1:\n",
    "            # 存在图片\n",
    "            image_path = chunks[0]\n",
    "            context = chunks[1]\n",
    "            img_base64 = encode_image(image_path)\n",
    "            display(HTML(f'\\n<img src=\"data:image/jpeg;base64,{img_base64}\"/>\\n'))\n",
    "            display(HTML(markdown.markdown(context)))\n",
    "        else:\n",
    "            display(HTML(markdown.markdown(part)))\n",
    "\n",
    "\n",
    "def resize_base64_image4tongyi(base64_string, max_size=(640, 480)):\n",
    "    '''\n",
    "    将Base64编码的图片进行缩放处理，并将缩放后的图片保存到本地文件系统，最后返回保存路径\n",
    "    base64_string: Base64编码的图片字符串\n",
    "        它是一个字符串，包含字母(A-Z, a-z)、数字(0-9)以及特殊字符(+/=)\n",
    "        通常以类似\"data:image/png;base64,\"开头，后面跟着实际的Base64编码数据\n",
    "        例如： \"iVBORw0KGgoAAAANSUhEUgAAAAoAAAAKCAYAAACNMs+9AAAAFUlEQVR42mP8//+/JgMRQBOgLN4aAKkDZQ0V6XQZAAAAAElFTkSuQmCC\"\n",
    "    max_size: 一个元组，表示图片缩放后的最大尺寸，默认为(640, 480)\n",
    "    '''\n",
    "    # 解析图片\n",
    "    img_data = base64.b64decode(base64_string)  # 将Base64字符串解码为二进制图片数据\n",
    "    img = Image.open(io.BytesIO(img_data))  # 使用PIL库的Image.open()和io.BytesIO()从二进制数据创建图片对象\n",
    "\n",
    "    width, height = img.size\n",
    "    ratio = max(max_size[0] / width, max_size[1] / height)\n",
    "\n",
    "    # 计算按比例缩放后的宽高\n",
    "    new_width = int(width * ratio)\n",
    "    new_height = int(height * ratio)\n",
    "\n",
    "    # 缩放 Image.LANCZOS: 重采样滤波器\n",
    "    resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "\n",
    "    # 保存图片到指定路径\n",
    "    out_path = os.path.join(RESIZE_IMAGE_DIR, str(uuid.uuid4()) + \".jpg\")\n",
    "    resized_img.save(out_path)\n",
    "    # 图片地址\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def is_base64(s):\n",
    "    \"\"\"检查是否为base64数据\"\"\"\n",
    "    # 检查是否为字符串\n",
    "    if not isinstance(s, str):\n",
    "        return False\n",
    "\n",
    "    # 检查是否只包含 base64 允许的字符\n",
    "    if not re.match(r'^[A-Za-z0-9+/]*={0,2}$', s):\n",
    "        return False\n",
    "\n",
    "    # 检查长度是否是 4 的倍数\n",
    "    if len(s) % 4 != 0:\n",
    "        return False\n",
    "\n",
    "    # 尝试解码\n",
    "    try:\n",
    "        base64.b64decode(s, validate=True)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def split_image_text_types(docs):\n",
    "    \"\"\"\n",
    "    将文档和图片内容切分，分别存储到各自的列表中\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    text = []\n",
    "    for doc in docs:\n",
    "        content = doc.page_content\n",
    "        if is_base64(content):\n",
    "            # 缩放图片\n",
    "            resize_image = resize_base64_image4tongyi(content)\n",
    "            images.append(resize_image)\n",
    "        else:\n",
    "            text.append(content)\n",
    "\n",
    "    return {\"images\": images, \"texts\": text}"
   ],
   "id": "8ade85d3f4e387b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.3 解析文件\n",
    "# 如果图片提取目录存在则删除重建\n",
    "if os.path.exists(IMAGE_OUT_DIR):\n",
    "    shutil.rmtree(IMAGE_OUT_DIR)\n",
    "os.makedirs(IMAGE_OUT_DIR)\n",
    "\n",
    "print('\\n开始解析pdf文档' + '-' * 100)\n",
    "pdf_data = partition_pdf(\n",
    "    filename=PDF_PATH,\n",
    "    extract_images_in_pdf=True,  # 提取图片\n",
    "    infer_table_structure=True,  # 启用表格结构识别\n",
    "    max_characters=4000,  # 每个文本块最大字符数\n",
    "    new_after_n_chars=3800,  # 达到3800字符后分新块\n",
    "    combine_text_under_n_chars=2000,  # 合并小于2000字符的文本块\n",
    "    chunking_strategy=\"by_title\",  # 按标题分块\n",
    "    extract_image_block_output_dir=IMAGE_OUT_DIR,  # 图片提取路径\n",
    ")\n",
    "\n",
    "print(\"pdf_data 格式：[CompositeElement ，table，CompositeElement ，table,...]: \")\n",
    "print(pdf_data)\n",
    "print(\"查看 CompositeElement\" + \"-\" * 100)\n",
    "print(pdf_data[0].metadata.orig_elements)\n",
    "print(\"查看 CompositeElement 的子节点\" + \"-\" * 100)\n",
    "print(pdf_data[0].metadata.orig_elements[1])"
   ],
   "id": "90e463494f2b6466",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.4 提取表格与文本\n",
    "tables = []\n",
    "texts = []\n",
    "for element in pdf_data:\n",
    "    if isinstance(element, Table):\n",
    "        tables.append(str(element))\n",
    "    elif isinstance(element, CompositeElement):\n",
    "        texts.append(str(element))\n",
    "print(f\"表格元素：{len(tables)}  文本元素：{len(texts)}\")\n"
   ],
   "id": "67434ebdeee2c361",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.5 多模态嵌入模型\n",
    "class MultiDashScopeEmbeddings(BaseModel, Embeddings):\n",
    "    model: str = \"multimodal-embedding-v1\"\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        text_features = []\n",
    "        for text in texts:\n",
    "            resp = dashscope.MultiModalEmbedding.call(model=self.model, input=[{'text': text}])\n",
    "            while resp.output is None:\n",
    "                print(f\"{text} 向量化失败！\")\n",
    "                resp = dashscope.MultiModalEmbedding.call(model=self.model, input=[{'text': text}])\n",
    "\n",
    "            embeddings_list = resp.output['embeddings'][0]['embedding']\n",
    "            text_features.append(embeddings_list)\n",
    "        return text_features\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        resp = dashscope.MultiModalEmbedding.call(model=self.model, input=[{'text': text}])\n",
    "        while resp.output is None:\n",
    "            print(f\"{text} 向量化失败！\")\n",
    "            resp = dashscope.MultiModalEmbedding.call(model=self.model, input=[{'text': text}])\n",
    "\n",
    "        embeddings_list = resp.output['embeddings'][0]['embedding']\n",
    "        return embeddings_list\n",
    "\n",
    "    def embed_image(self, uris: List[str]) -> List[List[float]]:\n",
    "        image_features = []\n",
    "        for uri in uris:\n",
    "            # 阿里dashscope SDK要求传递图片的地址，对于本地图片dashscope SDK会将图片上传到OSS服务中：\n",
    "            local_image_uri = f\"file://{uri}\"\n",
    "            resp = dashscope.MultiModalEmbedding.call(model=self.model, input=[{\"image\": local_image_uri}])\n",
    "            while resp.output is None:\n",
    "                print(f\"{local_image_uri} 向量化失败！\")\n",
    "                resp = dashscope.MultiModalEmbedding.call(model=self.model, input=[{\"image\": local_image_uri}])\n",
    "\n",
    "            embeddings_list = resp.output['embeddings'][0]['embedding']\n",
    "            image_features.append(embeddings_list)\n",
    "        return image_features"
   ],
   "id": "b0bb47fe5850bb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.6 嵌入图片与文本\n",
    "# 1 向量数据库\n",
    "vectorstore = Chroma(collection_name=\"multi-vector\", embedding_function=MultiDashScopeEmbeddings())\n",
    "\n",
    "# 2 获得图片的地址\n",
    "image_uris = sorted(\n",
    "    [\n",
    "        os.path.join(IMAGE_OUT_DIR, image_name)\n",
    "        for image_name in os.listdir(IMAGE_OUT_DIR)\n",
    "        if image_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 3 添加图片 （存储图像base64数据与其向量数据）\n",
    "print(\"向量化图片\" + '-' * 100)\n",
    "if image_uris:\n",
    "    vectorstore.add_images(uris=image_uris)  # embedding_function 向量化\n",
    "# 4 添加文本与表格\n",
    "print(\"向量化表格\" + '-' * 100)\n",
    "if tables:\n",
    "    vectorstore.add_documents([Document(page_content=table) for table in tables])  # embedding_function 向量化\n",
    "print(\"向量化文本\" + '-' * 100)\n",
    "if texts:\n",
    "    vectorstore.add_documents([Document(page_content=text) for text in texts])\n",
    "print(\"数据添加完毕!!!\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ],
   "id": "540d200832535335",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.7 向量召回测试\n",
    "query = \"手电筒的电路模型\"\n",
    "docs = retriever.invoke(query)\n",
    "print(\"1. 向量召回结果数： \" + '-' * 100)\n",
    "print(len(docs))\n",
    "print(\"jupyter中展示图片：\")\n",
    "for doc in docs:\n",
    "    if is_base64(doc.page_content):\n",
    "        show_plt_img(doc.page_content)"
   ],
   "id": "421b20b7ec5c741a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.8 RAG构建\n",
    "# 1 缩放图片目录构建\n",
    "if os.path.exists(RESIZE_IMAGE_DIR):\n",
    "    shutil.rmtree(RESIZE_IMAGE_DIR)\n",
    "os.makedirs(RESIZE_IMAGE_DIR)\n",
    "\n",
    "\n",
    "# 2 提示构造函数\n",
    "def prompt_func(data_dict):\n",
    "    # \"context\":{\"images\": [\"缩放后的图片地址\",\"缩放后的图片地址\"], \"texts\": \"doc1\"}\n",
    "    # 提取图片与文本\n",
    "    images = data_dict[\"context\"][\"images\"]\n",
    "    texts = data_dict[\"context\"][\"texts\"]\n",
    "    messages = []\n",
    "    # 装载图片数据\n",
    "    for image in images:\n",
    "        # 样例：\n",
    "        # HumanMessage(content=[{'text': '请将图片标记标注为：`C:\\\\...\\\\35589c8d-e802-4f7b-a647-41ed1a0a3439.jpg`'},\n",
    "        # {'image': 'file://C:\\\\...\\\\35589c8d-e802-4f7b-a647-41ed1a0a3439.jpg'}],\n",
    "        # additional_kwargs={},\n",
    "        # response_metadata={}\n",
    "        # )\n",
    "        messages.append(\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"text\": f\"请将图片标记标注为：`{image}`\"},\n",
    "                    {\"image\": f\"file://{image}\"}\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 装载文本数据\n",
    "    formatted_texts = \"\\n\\n\".join(texts)\n",
    "    messages.append(\n",
    "        # 样例：\n",
    "        # HumanMessage(content=[{'text': '你是作为一名专...理排版，答案中提及的图片统一以`<image>传递的图片真实标记</image>`的形式呈现。\\n\n",
    "        # 用户的问题是：手电筒的电路模型\\n\\n参考的文本或者表格数据：\\n'}],\n",
    "        # additional_kwargs={},\n",
    "        # response_metadata={})]\n",
    "        HumanMessage(content=[\n",
    "            {\n",
    "                \"text\":\n",
    "                    \"你是作为一名专业的电气工程师和电路理论专家。你的任务是用中文回答与电路基本概念和定律相关的问题。\"  # 角色\n",
    "                    \"你将获得相关的图片与文本作为参考的上下文。这些图片和文本都是根据用户输入的关键词从向量数据库中检索获取的。\"\n",
    "                    \"请根据提供的图片和文本结合你丰富的知识与分析能力，提供一份全面的问题解答。\"  # 任务\n",
    "                    \"请将提供的图片标记自然融入答案阐述的对应位置进行合理排版，答案中提及的图片统一以`<image>传递的图片真实标记</image>`的形式呈现。\\n\\n\"  # 需求\n",
    "                    f\"用户的问题是：{data_dict['question']}\\n\\n\"\n",
    "                    \"参考的文本或者表格数据：\\n\"  # 样例\n",
    "                    f\"{formatted_texts}\"\n",
    "            }\n",
    "        ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print('*' * 200)\n",
    "    print(f\"messages: {messages}\")\n",
    "    print('*' * 200)\n",
    "    return messages\n",
    "\n",
    "\n",
    "# 3. 构建提示链\n",
    "chain = (\n",
    "        {\n",
    "            \"question\": RunnablePassthrough(),\n",
    "            \"context\": retriever | RunnableLambda(split_image_text_types)\n",
    "        } | RunnableLambda(prompt_func)\n",
    ")\n",
    "result = chain.invoke(query)\n",
    "print(\"2. 提示结果：\" + '-' * 100)\n",
    "print(result)\n",
    "\n",
    "# 4 构建RAG链\n",
    "llm = ChatTongyi(model=\"qwen-vl-max\")\n",
    "chain = (\n",
    "        {\n",
    "            \"question\": RunnablePassthrough(),\n",
    "            \"context\": retriever | RunnableLambda(split_image_text_types)\n",
    "        }\n",
    "        | RunnableLambda(prompt_func)\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = chain.invoke(query)\n",
    "print('3. RAG结果:' + '-' * 100)\n",
    "print(result)\n",
    "\n",
    "print(\"jupyter中展示结果:\" + '-' * 100)\n",
    "display_answer(result)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.基于多模态大模型（图像摘要 + 文本摘要 + 多模态生成）",
   "id": "b72522ce17c15db1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2.1 初始化\n",
    "import base64\n",
    "import os\n",
    "import shutil\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "import markdown\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_classic.retrievers import MultiVectorRetriever\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.stores import InMemoryStore\n",
    "from unstructured.documents.elements import Table, CompositeElement\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# 环境配置\n",
    "os.environ[\"TESSERACT_CMD\"] = \"/usr/bin/tesseract\"\n",
    "\n",
    "# 初始化\n",
    "BASE_DIR = \"/mnt/c/大模型/智泊大模型全栈教程总结/02-教材整理 L2/代码/Langchain/6.langchain高级RAG/data/\"\n",
    "RESOURCE_DIR = BASE_DIR + 'resources/'\n",
    "TOOLS_DIR = BASE_DIR + 'tools/'\n",
    "IMAGE_OUT_DIR = RESOURCE_DIR + 'images/'\n",
    "PDF_PATH = RESOURCE_DIR + \"978-7-5170-2271-8_1.pdf\"\n",
    "RESIZE_IMAGE_DIR = RESOURCE_DIR + \"temp\"\n"
   ],
   "id": "41ec1449de00acdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2.2 功能函数\n",
    "def is_image_path(filepath):\n",
    "    ''' 判断是否为图片地址 '''\n",
    "    try:\n",
    "        path = Path(filepath)\n",
    "        return all([\n",
    "            path.exists(),\n",
    "            path.is_file(),\n",
    "            path.suffix.lower() == '.jpg'\n",
    "        ])\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def resize_base64_image4tongyi(image_path, max_size=(640, 480)):\n",
    "    try:\n",
    "        # 打开图片\n",
    "        img = Image.open(image_path)\n",
    "        width, height = img.size\n",
    "        ratio = min(max_size[0] / width, max_size[1] / height)\n",
    "        # 计算按比例缩放后的宽高\n",
    "        new_width = int(width * ratio)\n",
    "        new_height = int(height * ratio)\n",
    "\n",
    "        # 缩放\n",
    "        resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "        # 保存图片到指定路径\n",
    "        out_path = out_path = os.path.join(RESIZE_IMAGE_DIR, str(uuid.uuid4()) + \".jpg\")\n",
    "        resized_img.save(out_path)\n",
    "        # 图片地址\n",
    "        return out_path\n",
    "    except Exception as e:\n",
    "        print(f\"处理图片时出错: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def split_image_text_types(docs):\n",
    "    \"\"\"\n",
    "    拆分图像和文本\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    texts = []\n",
    "    # docs：文本内容和图片地址\n",
    "    for doc in docs:\n",
    "        if is_image_path(doc):\n",
    "            doc = resize_base64_image4tongyi(doc)\n",
    "            images.append(doc)\n",
    "        else:\n",
    "            texts.append(doc)\n",
    "    return {\"images\": images, \"texts\": texts}\n",
    "\n",
    "\n",
    "def show_plt_img(img_base64):\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "    display(HTML(image_html))\n",
    "\n",
    "\n",
    "def encode_image(img_path):\n",
    "    with open(img_path, \"rb\") as img_file:\n",
    "        img_data = img_file.read()\n",
    "        img_base64 = base64.b64encode(img_data).decode('utf-8')\n",
    "        return img_base64\n",
    "\n",
    "\n",
    "def display_answer(text: str):\n",
    "    start_tag = \"<image>\"\n",
    "    end_tag = \"</image>\"\n",
    "    parts = text.split(start_tag)\n",
    "    for part in parts:\n",
    "        # 再根据</image>标签 分割文本：xxx => ['xxx'], xxx</image> => ['xxx','']\n",
    "        chunks = part.split(end_tag)\n",
    "        if len(chunks) > 1:\n",
    "            # 存在图片\n",
    "            image_path = chunks[0]\n",
    "            context = chunks[1]\n",
    "            img_base64 = encode_image(image_path)\n",
    "            display(HTML(f'\\n<img src=\"data:image/jpeg;base64,{img_base64}\"/>\\n'))\n",
    "            # display(HTML(context.replace(\"\\n\", \"<br/>\")))\n",
    "            display(HTML(markdown.markdown(context)))\n",
    "        else:\n",
    "            display(HTML(markdown.markdown(part)))\n"
   ],
   "id": "d58b3d60ce2e5240",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2.3 数据加载\n",
    "# 如果图片提取目录存在则删除重建\n",
    "if os.path.exists(IMAGE_OUT_DIR):\n",
    "    shutil.rmtree(IMAGE_OUT_DIR)\n",
    "os.makedirs(IMAGE_OUT_DIR)\n",
    "\n",
    "print('\\n开始解析pdf文档' + '-' * 100)\n",
    "pdf_data = partition_pdf(\n",
    "    filename=PDF_PATH,\n",
    "    extract_images_in_pdf=True,  # 提取图片\n",
    "    infer_table_structure=True,  # 启用表格结构识别\n",
    "    max_characters=4000,  # 每个文本块最大字符数\n",
    "    new_after_n_chars=3800,  # 达到3800字符后分新块\n",
    "    combine_text_under_n_chars=2000,  # 合并小于2000字符的文本块\n",
    "    chunking_strategy=\"by_title\",  # 按标题分块\n",
    "    extract_image_block_output_dir=IMAGE_OUT_DIR,  # 图片提取路径\n",
    ")"
   ],
   "id": "8317ed76edc2d11f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2.4 提取表格与文本\n",
    "tables = []\n",
    "texts = []\n",
    "for element in pdf_data:\n",
    "    if isinstance(element, Table):\n",
    "        tables.append(str(element))\n",
    "    elif isinstance(element, CompositeElement):\n",
    "        texts.append(str(element))\n",
    "print(f\"表格元素：{len(tables)}  文本元素：{len(texts)}\")\n",
    "\n",
    "# 4. 生成文本和表格摘要\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"你是一位负责生成表格和文本摘要以供检索的助理。\"  # 角色\n",
    "    \"这些摘要将被嵌入并用于检索原始文本或表格元素。\"\n",
    "    \"请提供表格或文本的简明摘要，该摘要已针对检索进行了优化。表格或文本：{document}\"  # 任务\n",
    ")"
   ],
   "id": "ddadc265f27aee48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2.5 使用大模型生成文本摘要\n",
    "model = ChatTongyi(model=\"qwen-max\")\n",
    "summarize_chain = {\"document\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 5})\n",
    "table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\n",
    "\n",
    "# 生成图片摘要\n",
    "def image_summarize(image_path):\n",
    "    \"\"\"生成图片摘要\"\"\"\n",
    "    chat = ChatTongyi(model=\"qwen-vl-max\")\n",
    "    local_image_path = f\"file://{image_path}\"\n",
    "    response = chat.invoke(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"text\": \"你是一名负责生成图像摘要以便检索的助理。这些摘要将被嵌入并用于检索原始图像。\"  # 角色\n",
    "                             \"请生成针对检索进行了优化的简洁的图像摘要。\"},  # 任务\n",
    "                    {\"image\": local_image_path}\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return response.content\n",
    "\n",
    "\n",
    "# 检索图片摘要获得图片地址\n",
    "img_list = []  # 原图片地址\n",
    "image_summaries = []  # 图片摘要\n",
    "for img_file in sorted(os.listdir(IMAGE_OUT_DIR)):\n",
    "    if img_file.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(IMAGE_OUT_DIR, img_file)\n",
    "        img_list.append(img_path)\n",
    "        # 生成图片摘要\n",
    "        image_summaries.append(image_summarize(img_path)[0][\"text\"])"
   ],
   "id": "b7f1f68890e279fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2.6 构建向量索引（摘要索引）\n",
    "embeddings_model = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v1\",\n",
    ")\n",
    "\n",
    "# 创建向量数据库（用于存储摘要）\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"multi_model\",\n",
    "    embedding_function=embeddings_model\n",
    ")\n",
    "\n",
    "# 创建内存存储（用于存储原内容）\n",
    "docstore = InMemoryStore()\n",
    "# 将摘要存储入库\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "def add_documents(doc_summaries, doc_contents):\n",
    "    if not doc_summaries or not doc_contents:\n",
    "        print(\"警告：文档摘要或内容为空，跳过添加操作。\")\n",
    "        return\n",
    "\n",
    "    if len(doc_summaries) != len(doc_contents):\n",
    "        print(\"警告：文档摘要和内容的数量不匹配，跳过添加操作。\")\n",
    "        return\n",
    "\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
    "    summary_docs = [\n",
    "        Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "        for i, s in enumerate(doc_summaries)\n",
    "    ]\n",
    "    vectorstore.add_documents(summary_docs)\n",
    "    docstore.mset(list(zip(doc_ids, doc_contents)))\n",
    "\n",
    "\n",
    "add_documents(text_summaries, texts)\n",
    "add_documents(table_summaries, tables)\n",
    "add_documents(image_summaries, img_list)\n",
    "\n",
    "# 构建多向量检索（摘要索引）\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    id_key=id_key,\n",
    "    search_kwargs={\"k\": 7}\n",
    ")"
   ],
   "id": "d38ed7801c8d5286",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2.7.RAG构建\n",
    "# 构建缩放图片存放目录\n",
    "if os.path.exists(RESIZE_IMAGE_DIR):\n",
    "    shutil.rmtree(RESIZE_IMAGE_DIR)\n",
    "os.makedirs(RESIZE_IMAGE_DIR)\n",
    "\n",
    "\n",
    "# RAG构建\n",
    "def prompt_func(data_dict):\n",
    "    # \"context\":{\"images\": [\"缩放后的图片地址\",\"缩放后的图片地址\"], \"texts\": \"doc1\"}\n",
    "    # 提取图片与文本\n",
    "    images = data_dict[\"context\"][\"images\"]\n",
    "    texts = data_dict[\"context\"][\"texts\"]\n",
    "    messages = []\n",
    "    # 装载图片数据\n",
    "    for image in images:\n",
    "        messages.append(\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"text\": f\"请将图片标记标注为：`{image}`\"},\n",
    "                    {\"image\": f\"file://{image}\"}\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 装载文本数据\n",
    "    formatted_texts = \"\\n\\n\".join(texts)\n",
    "    # 该提示词可优化，如加入少量样本，让大模型输出更稳定\n",
    "    messages.append(\n",
    "        HumanMessage(content=[\n",
    "            {\n",
    "                \"text\":\n",
    "                    \"你是作为一名专业的电气工程师和电路理论专家。你的任务是用中文回答与电路基本概念和定律相关的问题。\"  # 角色\n",
    "                    \"你将获得相关的图片与文本作为参考的上下文。这些图片和文本都是根据用户输入的关键词从向量数据库中检索获取的。\"\n",
    "                    \"请根据提供的图片和文本结合你丰富的知识与分析能力，提供一份全面的问题解答。\"  # 任务\n",
    "                    \"请将提供的图片标记自然融入答案阐述的对应位置进行合理排版，答案中提及的图片统一以`<image>传递的图片真实标记</image>`的形式呈现。\\n\\n\"  # 限制\n",
    "                    f\"用户的问题是：{data_dict['question']}\\n\\n\"\n",
    "                    \"参考的文本或者表格数据：\\n\"\n",
    "                    f\"{formatted_texts}\"\n",
    "            }\n",
    "        ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print('*' * 200)\n",
    "    print(f\"messages: {messages}\")\n",
    "    print('*' * 200)\n",
    "    return messages\n",
    "\n",
    "\n",
    "# 千问视觉模型（多模态）\n",
    "llm = ChatTongyi(model=\"qwen-vl-max\")\n",
    "chain = (\n",
    "        {\n",
    "            \"question\": RunnablePassthrough(),\n",
    "            \"context\": retriever | RunnableLambda(split_image_text_types)\n",
    "        }\n",
    "        | RunnableLambda(prompt_func)\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ],
   "id": "a1f1d82353c3c333",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2.8 效果展示\n",
    "# 向量召回展示\n",
    "query = \"介绍下手电筒的电路模型\"\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "print(\"1. 向量召回结果展示在jupyter中\" + '-' * 100)\n",
    "for doc in docs:\n",
    "    if is_image_path(doc):\n",
    "        show_plt_img(encode_image(doc))\n",
    "\n",
    "# RAG召回展示\n",
    "result = chain.invoke(query)\n",
    "print(\"2. RAG召回结果\" + '-' * 100)\n",
    "display_answer(result)\n"
   ],
   "id": "eee1eba6146c74e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.基于多模态大模型（图像摘要 + 文本向量检索 + 文本生成）",
   "id": "24b3ada358c3a0d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 3.1 初始化\n",
    "import base64\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import uuid\n",
    "\n",
    "from IPython.display import HTML, display, Markdown\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_classic.retrievers import MultiVectorRetriever\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_community.embeddings.dashscope import DashScopeEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.stores import InMemoryStore\n",
    "from unstructured.documents.elements import Image as ImageElement\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# 环境配置\n",
    "os.environ[\"TESSERACT_CMD\"] = \"/usr/bin/tesseract\"\n",
    "\n",
    "# 1. 初始化\n",
    "BASE_DIR = \"/mnt/c/大模型/智泊大模型全栈教程总结/02-教材整理 L2/代码/Langchain/6.langchain高级RAG/data/\"\n",
    "RESOURCE_DIR = BASE_DIR + 'resources/'\n",
    "TOOLS_DIR = BASE_DIR + 'tools/'\n",
    "IMAGE_OUT_DIR = RESOURCE_DIR + 'images/'\n",
    "PDF_PATH = RESOURCE_DIR + \"978-7-5170-2271-8_1.pdf\"\n",
    "RESIZE_IMAGE_DIR = RESOURCE_DIR + \"temp\""
   ],
   "id": "b024a850c24a2428",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 2. 加载pdf\n",
    "# 如果图片提取目录存在则删除重建\n",
    "if os.path.exists(IMAGE_OUT_DIR):\n",
    "    shutil.rmtree(IMAGE_OUT_DIR)\n",
    "os.makedirs(IMAGE_OUT_DIR)\n",
    "\n",
    "# 使用unstructured库解析PDF文档(需要科学上网)\n",
    "pdf_data = partition_pdf(\n",
    "    filename=PDF_PATH,\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,  # 启用表格结构识别\n",
    "    max_characters=4000,  # 每个文本块最大字符数\n",
    "    new_after_n_chars=3800,  # 达到3800字符后分新块\n",
    "    combine_text_under_n_chars=2000,  # 合并小于2000字符的文本块\n",
    "    chunking_strategy=\"by_title\",  # 按标题分块\n",
    "    extract_image_block_output_dir=IMAGE_OUT_DIR,  # 图片提取路径\n",
    ")"
   ],
   "id": "a34274d6e58d35e9",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 3. 生成摘要  生成文本和表格摘要\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"你是一位负责生成表格和文本摘要以供检索的助理。\"  # 角色\n",
    "    \"这些摘要将被嵌入并用于检索原始文本或表格元素。\"\n",
    "    \"请提供表格或文本的简明摘要，该摘要已针对检索进行了优化。表格或文本：{document}\"  # 任务\n",
    ")\n",
    "\n",
    "# 使用大模型生成文本摘要\n",
    "model = ChatTongyi(model=\"qwen-max\")\n",
    "summarize_chain = {\"document\": lambda x: x.text} | prompt | model | StrOutputParser()\n",
    "summaries = summarize_chain.batch(pdf_data, {\"max_concurrency\": 5})\n",
    "\n",
    "\n",
    "def image_summarize(image_path):\n",
    "    \"\"\"生成图片摘要\"\"\"\n",
    "    chat = ChatTongyi(model=\"qwen-vl-max\")\n",
    "    local_image_path = f\"file://{image_path}\"\n",
    "    print(f\"生成摘要:{image_path}\")\n",
    "    response = chat.invoke(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\n",
    "                        \"text\": \"你是一名负责生成图像摘要以便检索的助理。这些摘要将被嵌入并用于检索原始图像。请生成针对检索进行了优化的简洁的图像摘要。\"},\n",
    "                    {\"image\": local_image_path}\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return response.content\n",
    "\n",
    "\n",
    "image_summaries = []\n",
    "# image_list = []\n",
    "for element in pdf_data:\n",
    "    orig_elements = element.metadata.orig_elements\n",
    "    length = len(orig_elements)\n",
    "    for i, orig_element in enumerate(orig_elements):\n",
    "        # 图片元素\n",
    "        if isinstance(orig_element, ImageElement):\n",
    "            image_path = orig_element.metadata.to_dict()[\"image_path\"]\n",
    "            # image_list.append(orig_element)\n",
    "            # 将图片摘要记录在图片元素的text属性中\n",
    "            summarizes = image_summarize(image_path)[0][\"text\"]\n",
    "            orig_element.text = summarizes\n",
    "            image_summaries.append(summarizes)"
   ],
   "id": "1b416791cf94f45c",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# 4. 构建索引\n",
    "embeddings_model = DashScopeEmbeddings(model=\"text-embedding-v1\")\n",
    "# 创建向量数据库（用于存储摘要）\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"multi_model_opt\",\n",
    "    embedding_function=embeddings_model\n",
    ")\n",
    "# 创建内存存储（用于存储原内容）\n",
    "docstore = InMemoryStore()\n",
    "# 将摘要存储入库\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "\n",
    "def add_documents(doc_summaries, doc_contents):\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
    "    summary_docs = [\n",
    "        Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "        for i, s in enumerate(doc_summaries)\n",
    "    ]\n",
    "    vectorstore.add_documents(summary_docs)\n",
    "    docstore.mset(list(zip(doc_ids, doc_contents)))\n",
    "\n",
    "\n",
    "# 不再单独放入图片摘要??\n",
    "add_documents(summaries, pdf_data)  # PDF Element"
   ],
   "id": "6b81a624ecf13dc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# 5. 构建多向量检索（摘要索引）\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    id_key=id_key,\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n"
   ],
   "id": "7e9f5689a8ff40ee",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 6. RAG构建\n",
    "def split_image_text_types(docs):\n",
    "    texts = []\n",
    "    # 注意：doc为PDF Element\n",
    "    for doc in docs:\n",
    "        text = ''\n",
    "        # 从文档元数据中获取原始元素列表，这些元素可能包含文本、图片等不同类型\n",
    "        orig_element = doc.metadata.orig_elements\n",
    "        for element in orig_element:\n",
    "            # 是否为图片元素\n",
    "            if isinstance(element, ImageElement):\n",
    "                # 图片元素用标记包裹  src=图片路径  element.text=图片相关文本  例如： <image src=\"/path/to/image.png\">图片描述文字</image>\n",
    "                text += f'<image src=\"{element.metadata.image_path}\">{element.text}</image>'\n",
    "            else:\n",
    "                # 其他元素直接放入文本\n",
    "                text += element.text\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "\n",
    "def prompt_func(data_dict):\n",
    "    question = data_dict[\"question\"]\n",
    "    context = data_dict[\"context\"]\n",
    "    # 装载数据\n",
    "    formatted_texts = \"\\n\\n\".join(context)\n",
    "\n",
    "    prompt = (\"你是作为一名专业的电气工程师和电路理论专家。你的任务是用中文回答与电路基本概念和定律相关的问题。\"\n",
    "              \"你将获得相关文档作为参考的上下文。这些文档都是根据用户输入的关键词从向量数据库中检索获取的。\"\n",
    "              \"请根据提供的文档结合你丰富的知识与分析能力，提供一份全面的问题解答。\"\n",
    "              r\"请返回Markdown格式数据，并且当涉及到数学公式时，请使用正确的LaTeX语法来编写这些公式，对于行内公式应该以单个美元符号`$`;对于独立成行的公式，使用双美元符号`$$`包裹。例如，行内公式：`$a = \\frac{1}{2}$`,而独立成行的公式则是：`$$ a = \\frac{1}{2} $$`。\"\n",
    "              \"请将提供的文档中的图片`<image src='...'>`(不包括`<image>`)到`</image>`中间的文字，在需要时自然融入答案阐述的对应位置进行合理排版。\\n\\n\"\n",
    "              f\"用户的问题是：\\n{question}\\n\\n\"\n",
    "              \"参考的文本或者表格数据：\\n\"\n",
    "              f\"{formatted_texts}\")\n",
    "\n",
    "    print('*' * 200)\n",
    "    print(f\"prompt: {prompt}\")\n",
    "    print('*' * 200)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "llm = ChatTongyi(model=\"qwen-max\")\n",
    "chain = (\n",
    "        {\n",
    "            \"question\": RunnablePassthrough(),\n",
    "            \"context\": retriever | RunnableLambda(split_image_text_types)\n",
    "        }\n",
    "        | RunnableLambda(prompt_func)\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ],
   "id": "bc5067eca192176b",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# 7. 效果展示\n",
    "result = chain.invoke(\"介绍下电路模型\")\n",
    "\n",
    "\n",
    "def encode_image(img_path):\n",
    "    with open(img_path, \"rb\") as img_file:\n",
    "        img_data = img_file.read()\n",
    "        img_base64 = base64.b64encode(img_data).decode('utf-8')\n",
    "        return img_base64\n",
    "\n",
    "\n",
    "def display_answer(text: str):\n",
    "    # 正则表达式：用于匹配 <image src=\"xxx\"> 并捕获 src 属性的值\n",
    "    pattern = r'(<image src=\"([^\"]*)\">)'\n",
    "    # abc<image src=\"xxx\">def -》 [\"abc\", \"<image src=\"xxx\">\", \"xxx\", \"def\"]\n",
    "    chunks = re.split(pattern, text)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # 文本内容\n",
    "        if i % 3 == 0:\n",
    "            display(Markdown(chunk.replace(\"</image>\", \"\")))\n",
    "        elif i % 3 == 2:\n",
    "            # image_path = re.search(r'src=\"([^\"]*)\"', chunk).group(1) 1% 3==1\n",
    "            img_base64 = encode_image(chunk)\n",
    "            display(HTML(f'\\n<img src=\"data:image/jpeg;base64,{img_base64}\"/>\\n'))\n",
    "\n",
    "\n",
    "print('RAG结果展示:' + '-' * 100)\n",
    "display_answer(result)\n"
   ],
   "id": "52e74cc56375fa57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
