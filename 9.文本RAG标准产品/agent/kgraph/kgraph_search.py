"""
çŸ¥è¯†å›¾è°±æ£€ç´¢æ¨¡å—
å‚è€ƒmilvusæ¨¡å—çš„å®ç°ï¼Œæä¾›å›¾è°±æ£€ç´¢å·¥å…·
"""
import json
import logging
import sys
from pathlib import Path
from typing import List
from typing import TYPE_CHECKING

from langchain.tools import tool
from langchain_core.documents import Document
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import SystemMessage, ToolMessage, HumanMessage
from langgraph.prebuilt import ToolNode

# æ·»åŠ å½“å‰æ¨¡å—ç›®å½•åˆ° Python è·¯å¾„ï¼ˆæ”¯æŒç›´æ¥è¿è¡Œï¼‰
current_dir = Path(__file__).parent.parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

# å¯¼å…¥é…ç½®å’Œå·¥å…·å‡½æ•°
try:
    # å°è¯•ç›¸å¯¹å¯¼å…¥ï¼ˆå½“ä½œä¸ºåŒ…å¯¼å…¥æ—¶ï¼‰
    from ...prompts.templates import get_prompt_template
    from ...config.models import AppConfig
    from ..utils import json_to_list_document, _should_call_tool
    from .neo4j_connection import Neo4jConnection
    from .graph_searcher import GraphSearcher
except ImportError:
    # å›é€€åˆ°ç›´æ¥å¯¼å…¥ï¼ˆå½“ç›´æ¥è¿è¡Œæ–‡ä»¶æ—¶ï¼‰
    from prompts.templates import get_prompt_template
    from config.models import AppConfig
    from agent.utils import json_to_list_document, _should_call_tool
    from kgraph.neo4j_connection import Neo4jConnection
    from kgraph.graph_searcher import GraphSearcher

if TYPE_CHECKING:
    from typing_extensions import TypedDict


    class SearchMessagesState(TypedDict, total=False):
        query: str
        main_messages: List
        other_messages: List
        docs: List[Document]
        answer: str
        retry: int
        final: str
        judge_result: str

logger = logging.getLogger(__name__)


def llm_kgraph_search(
        state: "SearchMessagesState",
        llm: BaseChatModel,
        kgraph_tool_node: ToolNode,
        show_debug: bool
) -> "SearchMessagesState":
    """
    çŸ¥è¯†å›¾è°±æ£€ç´¢èŠ‚ç‚¹

    ========== åŠŸèƒ½è¯´æ˜ ==========
    è¯¥èŠ‚ç‚¹è´Ÿè´£ï¼š
    1. æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢ï¼Œè®©LLMåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨çŸ¥è¯†å›¾è°±æ£€ç´¢å·¥å…·
    2. å¦‚æœéœ€è¦ï¼Œæ‰§è¡Œå›¾è°±æ£€ç´¢å¹¶è·å–ç›¸å…³å®ä½“å’Œå…³ç³»
    3. å°†æ£€ç´¢åˆ°çš„å®ä½“/å…³ç³»è½¬æ¢ä¸ºDocumentå¯¹è±¡æ·»åŠ åˆ°çŠ¶æ€ä¸­ä¾›åç»­RAGä½¿ç”¨
    """
    query = state["query"]

    if show_debug:
        logger.info(f"å¼€å§‹å›¾è°±æ£€ç´¢èŠ‚ç‚¹ï¼ŒæŸ¥è¯¢: {query}")

    # è°ƒç”¨LLMï¼Œè®©å…¶åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å›¾è°±æ£€ç´¢å·¥å…·
    kg_ai = llm.invoke([
        SystemMessage(content=get_prompt_template("call_kgraph")["system"]),
        HumanMessage(content=get_prompt_template("call_kgraph")["user"].format(query=query))
    ])
    state["other_messages"].append(kg_ai)

    # æ£€æŸ¥LLMæ˜¯å¦å†³å®šè°ƒç”¨å·¥å…·
    if _should_call_tool(kg_ai):
        if show_debug:
            tool_calls = getattr(kg_ai, 'tool_calls', None)
            if tool_calls and len(tool_calls) > 0:
                try:
                    if hasattr(tool_calls[0], 'args'):
                        args = tool_calls[0].args
                    elif isinstance(tool_calls[0], dict):
                        args = tool_calls[0].get('args', {})
                    else:
                        args = {}
                    logger.info(f"å¼€å§‹å›¾è°±æ£€ç´¢ï¼Œæ£€ç´¢å‚æ•°ï¼š{args}")
                except Exception as e:
                    logger.error(f"è·å–å·¥å…·å‚æ•°å¤±è´¥: {e}")

        try:
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            tool_msgs: ToolMessage = kgraph_tool_node.invoke([kg_ai])
            state["other_messages"].append(tool_msgs)

            # å°†ToolMessageä¸­çš„JSONå­—ç¬¦ä¸²è½¬æ¢ä¸ºDocumentå¯¹è±¡åˆ—è¡¨
            new_docs = json_to_list_document(tool_msgs[0].content)
            state["docs"].extend(new_docs)

            if show_debug:
                logger.info(f"å›¾è°±æ£€ç´¢åˆ° {len(new_docs)} æ¡æ–‡æ¡£")
                if len(state["docs"]) >= 2:
                    logger.info(
                        f"éƒ¨åˆ†ç¤ºä¾‹ï¼ˆå…±{len(state['docs'])}æ¡ï¼‰ï¼š\n\n{state['docs'][0].page_content[:200]}...\n\n{state['docs'][1].page_content[:200]}..."
                    )
                elif len(state["docs"]) == 1:
                    logger.info(f"ä»…æ£€ç´¢ä¸€æ¡æ•°æ®ï¼š\n\n{state['docs'][0].page_content[:200]}")
                else:
                    logger.warning("æœªæ£€ç´¢åˆ°ä»»ä½•å›¾è°±ä¿¡æ¯ï¼")
        except Exception as e:
            logger.error(f"å›¾è°±æ£€ç´¢è¿‡ç¨‹å‡ºé”™: {e}")

    return state


def create_kgraph_search_tool(
        config,
        power_model: BaseChatModel
):
    """
    åˆ›å»ºçŸ¥è¯†å›¾è°±æ£€ç´¢å·¥å…·èŠ‚ç‚¹

    Args:
        config: åº”ç”¨é…ç½®
        power_model: LLMå®ä¾‹

    Returns:
        tuple: (kgraph_search_tool, kgraph_search_llm, kgraph_tool_node)
    """
    if config.agent.kgraph_search_enabled is False:
        return None, None, None

    cnt = config.agent.kgraph_search_cnt

    # åˆ›å»ºNeo4jè¿æ¥
    neo4j_conn = Neo4jConnection(config)
    connected = neo4j_conn.connect()

    if not connected:
        logger.warning(f"Neo4jè¿æ¥å¤±è´¥: {neo4j_conn.uri}")
        return None, None, None

    # åˆ›å»ºå›¾è°±æ£€ç´¢å™¨
    graph_searcher = GraphSearcher(neo4j_conn)

    @tool("kgraph_search")
    def kgraph_search(query: str) -> str:
        """
        çŸ¥è¯†å›¾è°±æ£€ç´¢å·¥å…·

        Args:
            query: æ£€ç´¢æŸ¥è¯¢æ–‡æœ¬

        Returns:
            æ£€ç´¢ç»“æœçš„JSONå­—ç¬¦ä¸²
        """
        results = graph_searcher.search_graph(query, limit=cnt)
        # è½¬æ¢Documentå¯¹è±¡ä¸ºå­—å…¸åˆ—è¡¨
        results_dict = [{"page_content": doc.page_content, "metadata": doc.metadata} for doc in results]
        return json.dumps(results_dict, ensure_ascii=False)

    kgraph_search_tool = kgraph_search
    kgraph_search_llm = power_model.bind_tools([kgraph_search_tool])
    kgraph_tool_node = ToolNode([kgraph_search_tool])

    return kgraph_search_tool, kgraph_search_llm, kgraph_tool_node


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":

    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    print("=" * 60)
    print("çŸ¥è¯†å›¾è°±æ£€ç´¢ç¤ºä¾‹")
    print("=" * 60)

    try:
        # åŠ è½½é…ç½®
        from config.loader import load_config

        config = load_config()

        print(f"\nğŸ“Š é…ç½®ä¿¡æ¯:")
        print(f"   Neo4j URI: {config.neo4j.uri}")
        print(f"   æ•°æ®åº“: {config.neo4j.database}")

        # åˆ›å»ºNeo4jè¿æ¥
        print(f"\nğŸ”Œ è¿æ¥Neo4jæ•°æ®åº“...")
        neo4j_conn = Neo4jConnection(config)
        connected = neo4j_conn.connect()

        if not connected:
            print(f"âŒ Neo4jè¿æ¥å¤±è´¥: {neo4j_conn.uri}")
            print("   è¯·ç¡®ä¿Neo4jæœåŠ¡å·²å¯åŠ¨ï¼Œå¹¶æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„è¿æ¥ä¿¡æ¯")
            exit(1)

        print(f"âœ… Neo4jè¿æ¥æˆåŠŸ")

        # åˆ›å»ºå›¾è°±æ£€ç´¢å™¨
        graph_searcher = GraphSearcher(neo4j_conn)

        # ç¤ºä¾‹1: å…³é”®è¯æ£€ç´¢
        print(f"\n" + "=" * 60)
        print("ç¤ºä¾‹1: å…³é”®è¯æ£€ç´¢")
        print("=" * 60)
        keyword = "æ„Ÿå†’"
        print(f"æœç´¢å…³é”®è¯: '{keyword}'")
        docs = graph_searcher.search_by_keyword(keyword, limit=5)
        print(f"âœ… æ‰¾åˆ° {len(docs)} ä¸ªå®ä½“:")
        for i, doc in enumerate(docs, 1):
            print(f"   {i}. {doc.page_content}")

        # ç¤ºä¾‹2: å…³ç³»æ£€ç´¢
        print(f"\n" + "=" * 60)
        print("ç¤ºä¾‹2: å…³ç³»æ£€ç´¢")
        print("=" * 60)
        entity_name = "é˜¿å¸åŒ¹æ—"
        print(f"æŸ¥è¯¢å®ä½“: '{entity_name}' çš„å…³ç³»")
        docs = graph_searcher.search_by_relation(entity_name, limit=5)
        print(f"âœ… æ‰¾åˆ° {len(docs)} æ¡å…³ç³»:")
        for i, doc in enumerate(docs, 1):
            print(f"   {i}. {doc.page_content}")

        # ç¤ºä¾‹3: ç»¼åˆå›¾è°±æ£€ç´¢
        print(f"\n" + "=" * 60)
        print("ç¤ºä¾‹3: ç»¼åˆå›¾è°±æ£€ç´¢")
        print("=" * 60)
        keyword = "ç³–å°¿ç—…"
        print(f"ç»¼åˆæ£€ç´¢å…³é”®è¯: '{keyword}'")
        docs = graph_searcher.search_graph(keyword, limit=10)
        print(f"âœ… æ‰¾åˆ° {len(docs)} æ¡ç»“æœï¼ˆå®ä½“+å…³ç³»ï¼‰:")
        for i, doc in enumerate(docs, 1):
            print(f"   {i}. {doc.page_content}")

        # ç¤ºä¾‹4: æµ‹è¯•æ£€ç´¢å·¥å…·
        print(f"\n" + "=" * 60)
        print("ç¤ºä¾‹4: åˆ›å»ºæ£€ç´¢å·¥å…·å¹¶è°ƒç”¨")
        print("=" * 60)

        # åˆå§‹åŒ–LLM
        from langchain_openai import ChatOpenAI

        llm = ChatOpenAI(
            model=config.model.llm_model,
            temperature=config.llm.temperature,
            base_url=config.llm.base_url,
            api_key=config.llm.api_key or "dummy-key"
        )

        # åˆ›å»ºæ£€ç´¢å·¥å…·
        kgraph_tool, kgraph_llm, kgraph_tool_node = create_kgraph_search_tool(config, llm)

        if kgraph_tool is None:
            print("âš ï¸  å›¾è°±æ£€ç´¢å·¥å…·æœªå¯ç”¨")
        else:
            print(f"âœ… å›¾è°±æ£€ç´¢å·¥å…·åˆ›å»ºæˆåŠŸ")
            print(f"   å·¥å…·åç§°: {kgraph_tool.name}")
            print(f"   å·¥å…·æè¿°: {kgraph_tool.description}")

            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            print(f"\nğŸ” ä½¿ç”¨å·¥å…·æœç´¢: 'é«˜è¡€å‹'")
            from langchain_core.messages import HumanMessage

            result = kgraph_tool.invoke({"query": "é«˜è¡€å‹"})
            print(f"âœ… æ£€ç´¢ç»“æœï¼ˆå‰500å­—ç¬¦ï¼‰:")
            print(f"   {str(result)[:500]}...")

        # å…³é—­è¿æ¥
        neo4j_conn.close()
        print(f"\nâœ… è¿æ¥å·²å…³é—­")

        print(f"\n" + "=" * 60)
        print("å›¾è°±æ£€ç´¢ç¤ºä¾‹å®Œæˆ")
        print("=" * 60)

    except ImportError as e:
        print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
        print("   è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–: pip install -r requirements.txt")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback

        traceback.print_exc()
