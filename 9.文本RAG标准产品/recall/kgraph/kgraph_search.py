"""
çŸ¥è¯†å›¾è°±æ£€ç´¢æ¨¡å—
å‚è€ƒmilvusæ¨¡å—çš„å®ç°ï¼Œæä¾›å›¾è°±æ£€ç´¢å·¥å…·
"""
import json
import logging
from typing import List
from typing_extensions import TypedDict

from langchain.tools import tool
from langchain_core.documents import Document
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import SystemMessage, ToolMessage
from langgraph.prebuilt import ToolNode

from .kg_loader import KGraphConfigLoader
from .kg_templates import get_prompt_template
from .kg_utils import json_to_list_document, _should_call_tool
from .kgraph_searcher import GraphSearcher
from .neo4j_connection import Neo4jConnection


class KGraphRecallState(TypedDict, total=False):
    query: str
    other_messages: List
    docs: List[Document]


logger = logging.getLogger(__name__)


def llm_kgraph_search(
        state: "KGraphRecallState",
        llm: BaseChatModel,
        kgraph_tool_node: ToolNode,
        show_debug: bool
) -> "KGraphRecallState":
    """
    çŸ¥è¯†å›¾è°±æ£€ç´¢èŠ‚ç‚¹

    ========== åŠŸèƒ½è¯´æ˜ ==========
    è¯¥èŠ‚ç‚¹è´Ÿè´£ï¼š
    1. æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢ï¼Œè®©LLMåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨çŸ¥è¯†å›¾è°±æ£€ç´¢å·¥å…·
    2. å¦‚æœéœ€è¦ï¼Œæ‰§è¡Œå›¾è°±æ£€ç´¢å¹¶è·å–ç›¸å…³å®ä½“å’Œå…³ç³»
    3. å°†æ£€ç´¢åˆ°çš„å®ä½“/å…³ç³»è½¬æ¢ä¸ºDocumentå¯¹è±¡æ·»åŠ åˆ°çŠ¶æ€ä¸­ä¾›åç»­RAGä½¿ç”¨
    """
    print('-' * 60)
    print("å¼€å§‹å›¾è°±æ£€ç´¢")
    print('-' * 60)
    query = state["query"]

    if show_debug:
        logger.info(f"å¼€å§‹å›¾è°±æ£€ç´¢èŠ‚ç‚¹ï¼ŒæŸ¥è¯¢: {query}")

    # è°ƒç”¨LLMï¼Œè®©å…¶åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å›¾è°±æ£€ç´¢å·¥å…·
    kg_ai = llm.invoke([
        SystemMessage(content=get_prompt_template("call_kgraph")["system"]),
        HumanMessage(content=get_prompt_template("call_kgraph")["user"].format(query=query))
    ])
    state["other_messages"].append(kg_ai)

    # æ£€æŸ¥LLMæ˜¯å¦å†³å®šè°ƒç”¨å·¥å…·
    if _should_call_tool(kg_ai):
        if show_debug:
            tool_calls = getattr(kg_ai, 'tool_calls', None)
            if tool_calls and len(tool_calls) > 0:
                try:
                    if hasattr(tool_calls[0], 'args'):
                        args = tool_calls[0].args
                    elif isinstance(tool_calls[0], dict):
                        args = tool_calls[0].get('args', {})
                    else:
                        args = {}
                    logger.info(f"å¼€å§‹å›¾è°±æ£€ç´¢ï¼Œæ£€ç´¢å‚æ•°ï¼š{args}")
                except Exception as e:
                    logger.error(f"è·å–å·¥å…·å‚æ•°å¤±è´¥: {e}")

        try:
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            tool_msgs: ToolMessage = kgraph_tool_node.invoke([kg_ai])
            state["other_messages"].append(tool_msgs)

            # å°†ToolMessageä¸­çš„JSONå­—ç¬¦ä¸²è½¬æ¢ä¸ºDocumentå¯¹è±¡åˆ—è¡¨
            new_docs = json_to_list_document(tool_msgs[0].content)
            state["docs"].extend(new_docs)

            if show_debug:
                logger.info(f"å›¾è°±æ£€ç´¢åˆ° {len(new_docs)} æ¡æ–‡æ¡£")
                if len(state["docs"]) >= 2:
                    logger.info(
                        f"éƒ¨åˆ†ç¤ºä¾‹ï¼ˆå…±{len(state['docs'])}æ¡ï¼‰ï¼š\n\n{state['docs'][0].page_content[:200]}...\n\n{state['docs'][1].page_content[:200]}..."
                    )
                elif len(state["docs"]) == 1:
                    logger.info(f"ä»…æ£€ç´¢ä¸€æ¡æ•°æ®ï¼š\n\n{state['docs'][0].page_content[:200]}")
                else:
                    logger.warning("æœªæ£€ç´¢åˆ°ä»»ä½•å›¾è°±ä¿¡æ¯ï¼")
        except Exception as e:
            logger.error(f"å›¾è°±æ£€ç´¢è¿‡ç¨‹å‡ºé”™: {e}")

    return state


def create_kgraph_search_tool(
        kgraph_config_loader: KGraphConfigLoader,
        power_model: BaseChatModel
):
    """
    åˆ›å»ºçŸ¥è¯†å›¾è°±æ£€ç´¢å·¥å…·èŠ‚ç‚¹

    Args:
        kgraph_config_loader: å›¾è°±é…ç½®åŠ è½½å™¨
        power_model: LLMå®ä¾‹

    Returns:
        tuple: (kgraph_search_tool, kgraph_search_llm, kgraph_tool_node)
    """
    # é»˜è®¤å¯ç”¨çŸ¥è¯†å›¾è°±æœç´¢
    cnt = 10  # é»˜è®¤æ£€ç´¢10æ¡ç»“æœ
    neo4j_conn = Neo4jConnection(kgraph_config_loader)  # åˆ›å»ºNeo4jè¿æ¥
    connected = neo4j_conn.connect()

    if not connected:
        logger.warning(f"Neo4jè¿æ¥å¤±è´¥: {neo4j_conn.uri}")
        return None, None, None

    # åˆ›å»ºå›¾è°±æ£€ç´¢å™¨ï¼ˆä¼ å…¥åµŒå…¥é…ç½®ä»¥æ”¯æŒå‘é‡æ£€ç´¢ï¼‰
    # ä½¿ç”¨ text_dense é…ç½®ä½œä¸ºåµŒå…¥æ¨¡å‹
    embedding_config = {
        "provider": kgraph_config_loader.get("embedding.provider", "ollama"),
        "model": kgraph_config_loader.get("embedding.model", "nomic-embed-text"),
        "api_key": kgraph_config_loader.get("embedding.api_key", None),
        "base_url": kgraph_config_loader.get("embedding.base_url", "http://localhost:11434/v1")
    }
    graph_searcher = GraphSearcher(neo4j_conn, embedding_config=embedding_config)

    @tool("kgraph_search")
    def kgraph_search(query: str) -> str:
        """
        çŸ¥è¯†å›¾è°±æ£€ç´¢å·¥å…·

        Args:
            query: æ£€ç´¢æŸ¥è¯¢æ–‡æœ¬

        Returns:
            æ£€ç´¢ç»“æœçš„JSONå­—ç¬¦ä¸²
        """
        # ä½¿ç”¨å‘é‡æ£€ç´¢
        results = graph_searcher.search_graph_by_query(query_text=query, top_k=cnt)
        vdb_results = results.get("vdb_results", [])

        # è½¬æ¢ä¸ºDocumentå¯¹è±¡
        results_dict = [{"page_content": doc, "metadata": {"source": "knowledge_graph", "query": query}} for doc in vdb_results]
        return json.dumps(results_dict, ensure_ascii=False)

    kgraph_search_tool = kgraph_search
    kgraph_search_llm = power_model.bind_tools([kgraph_search_tool])
    kgraph_tool_node = ToolNode([kgraph_search_tool])

    return kgraph_search_tool, kgraph_search_llm, kgraph_tool_node


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":

    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    print("=" * 60)
    print("çŸ¥è¯†å›¾è°±æ£€ç´¢ç¤ºä¾‹")
    print("=" * 60)

    try:
        # åŠ è½½é…ç½®
        from kg_loader import KGraphConfigLoader

        config = KGraphConfigLoader()

        print(f"\nğŸ“Š é…ç½®ä¿¡æ¯:")
        print(f"   Neo4j URI: {config.neo4j_config.uri}")
        print(f"   æ•°æ®åº“: {config.neo4j_config.database}")

        # åˆ›å»ºNeo4jè¿æ¥
        print(f"\nğŸ”Œ è¿æ¥Neo4jæ•°æ®åº“...")
        neo4j_conn = Neo4jConnection(config)
        connected = neo4j_conn.connect()

        if not connected:
            print(f"âŒ Neo4jè¿æ¥å¤±è´¥: {neo4j_conn.uri}")
            print("   è¯·ç¡®ä¿Neo4jæœåŠ¡å·²å¯åŠ¨ï¼Œå¹¶æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„è¿æ¥ä¿¡æ¯")
            exit(1)

        print(f"âœ… Neo4jè¿æ¥æˆåŠŸ")

        # åˆ›å»ºå›¾è°±æ£€ç´¢å™¨
        embedding_config = {
            "provider": config.get("embedding.provider", "ollama"),
            "model": config.get("embedding.model", "nomic-embed-text"),
            "api_key": config.get("embedding.api_key", None),
            "base_url": config.get("embedding.base_url", "http://localhost:11434/v1")
        }
        graph_searcher = GraphSearcher(neo4j_conn, embedding_config=embedding_config)

        # ç¤ºä¾‹1: queryæ£€ç´¢
        print(f"\n" + "=" * 60)
        print("ç¤ºä¾‹1: å…³é”®è¯æ£€ç´¢")
        print("=" * 60)
        keyword = "æˆ¿é¢¤çš„æ²»ç–—ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ"
        print(f"æœç´¢å…³é”®è¯: '{keyword}'")
        dict = graph_searcher.search_graph_by_query(keyword, top_k=5)
        content = dict.get("content", "")
        print(f"  content: {content}")

        # ç¤ºä¾‹2: å…³ç³»æ£€ç´¢
        print(f"\n" + "=" * 60)
        print("ç¤ºä¾‹2: å…³ç³»æ£€ç´¢")
        print("=" * 60)
        entity_name = "é˜¿å¸åŒ¹æ—"
        print(f"æŸ¥è¯¢å®ä½“: '{entity_name}' çš„å…³ç³»")
        docs = graph_searcher.search_by_relation(entity_name, limit=5)
        print(f"âœ… æ‰¾åˆ° {len(docs)} æ¡å…³ç³»:")
        for i, doc in enumerate(docs, 1):
            print(f"   {i}. {doc.page_content}")

        # ç¤ºä¾‹3: å…³é”®è¯æ£€ç´¢
        print(f"\n" + "=" * 60)
        print("ç¤ºä¾‹3: ç»¼åˆå›¾è°±æ£€ç´¢")
        print("=" * 60)
        keyword = "ç³–å°¿ç—…"
        print(f"ç»¼åˆæ£€ç´¢å…³é”®è¯: '{keyword}'")
        result = graph_searcher.search_by_keyword(keyword, limit=10)
        print(f"âœ… æ‰¾åˆ° {len(result)} æ¡ç»“æœï¼ˆå®ä½“ï¼‰:")
        for i, doc in enumerate(result, 1):
            print(f"   {i}. {doc.page_content}")

        # ç¤ºä¾‹4: æµ‹è¯•æ£€ç´¢å·¥å…·
        print(f"\n" + "=" * 60)
        print("ç¤ºä¾‹4: åˆ›å»ºæ£€ç´¢å·¥å…·å¹¶è°ƒç”¨")
        print("=" * 60)

        # åˆå§‹åŒ–LLM
        from langchain_openai import ChatOpenAI

        llm = ChatOpenAI(
            model=config.llm_config.model,
            temperature=config.llm_config.temperature,
            base_url=config.llm_config.base_url,
            api_key=config.llm_config.api_key or "dummy-key"
        )

        # åˆ›å»ºæ£€ç´¢å·¥å…·
        kgraph_tool, kgraph_llm, kgraph_tool_node = create_kgraph_search_tool(config, llm)

        if kgraph_tool is None:
            print("âš ï¸  å›¾è°±æ£€ç´¢å·¥å…·æœªå¯ç”¨")
        else:
            print(f"âœ… å›¾è°±æ£€ç´¢å·¥å…·åˆ›å»ºæˆåŠŸ")
            print(f"   å·¥å…·åç§°: {kgraph_tool.name}")
            print(f"   å·¥å…·æè¿°: {kgraph_tool.description}")

            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            print(f"\nğŸ” ä½¿ç”¨å·¥å…·æœç´¢: 'é«˜è¡€å‹'")
            from langchain_core.messages import HumanMessage

            result = kgraph_tool.invoke({"query": "é«˜è¡€å‹"})
            print(f"âœ… æ£€ç´¢ç»“æœï¼ˆå‰500å­—ç¬¦ï¼‰:")
            print(f"   {str(result)[:500]}...")

        # å…³é—­è¿æ¥
        neo4j_conn.close()
        print(f"\nâœ… è¿æ¥å·²å…³é—­")

        print(f"\n" + "=" * 60)
        print("å›¾è°±æ£€ç´¢ç¤ºä¾‹å®Œæˆ")
        print("=" * 60)

    except ImportError as e:
        print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
        print("   è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–: pip install -r requirements.txt")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback

        traceback.print_exc()
